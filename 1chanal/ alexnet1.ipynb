{"cells":[{"cell_type":"markdown","metadata":{"id":"3BnbRO7ugk2Z"},"source":["# spilt"],"id":"3BnbRO7ugk2Z"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42175,"status":"ok","timestamp":1657025949971,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"idQkTJZDejiP","outputId":"aa152115-8801-4853-e1e2-2f3c110699b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"idQkTJZDejiP"},{"cell_type":"code","execution_count":2,"metadata":{"id":"bd0e5ef3","executionInfo":{"status":"ok","timestamp":1657025949972,"user_tz":-480,"elapsed":6,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"],"id":"bd0e5ef3"},{"cell_type":"markdown","metadata":{"id":"SHuCCF5Bgorp"},"source":["# test"],"id":"SHuCCF5Bgorp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"hSTWoAm8fIat","executionInfo":{"status":"ok","timestamp":1657025953388,"user_tz":-480,"elapsed":3421,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import torch.nn as nn\n","from torchvision import datasets,transforms\n","from torch.autograd import Variable"],"id":"hSTWoAm8fIat"},{"cell_type":"code","execution_count":5,"metadata":{"id":"QVC3JbajfP1L","executionInfo":{"status":"ok","timestamp":1657026060626,"user_tz":-480,"elapsed":946,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import skimage\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","torch.manual_seed(1)  # reproducible\n","torch.set_default_tensor_type(torch.DoubleTensor)\n","from PIL import Image\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n","])\n","class MyDataset(Dataset):\n","    def __init__(self, data,label):\n","        self.data = data #加载npy数据\n","        self.label = label\n","        self.transforms = transform #转为tensor形式\n","    def __getitem__(self, index):\n","        hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","        hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","        hdct= self.transforms(hdct)  #转为tensor形式\n","#         ldct= self.transforms(ldct)  #转为tensor形式\n","        return hdct, self.label[index] #返回数据还有标签\n","    def __len__(self):\n","        return self.data.shape[0] #返回数据的总个数"],"id":"QVC3JbajfP1L"},{"cell_type":"code","source":[""],"metadata":{"id":"7BVJUJ_hczCu"},"id":"7BVJUJ_hczCu","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"X37_O0J1GChl","executionInfo":{"status":"ok","timestamp":1657026094547,"user_tz":-480,"elapsed":2,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["#model.py\n","\n","import torch.nn as nn\n","import torch\n","\n","\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes=8, init_weights=False):   \n","        super(AlexNet, self).__init__()\n","        self.bn = nn.BatchNorm2d(32)\n","        self.features = nn.Sequential(  #打包\n","            nn.Conv2d(1, 24, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n","            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n","            nn.Conv2d(24, 64, kernel_size=5, padding=2),           # output[128, 27, 27]\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),          # output[192, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),          # output[192, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 32, kernel_size=3, padding=1),          # output[128, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(p=0.5),\n","            #全链接\n","            nn.Linear(32 * 6 * 6, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128, 64),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(64, num_classes),\n","        )\n","        if init_weights:\n","            self._initialize_weights()\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.bn(x)\n","        x = torch.flatten(x, start_dim=1) #展平   或者view()\n","        x = self.classifier(x)\n","        return self.logsoftmax(x)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n","                nn.init.constant_(m.bias, 0)\n"],"id":"X37_O0J1GChl"},{"cell_type":"code","execution_count":7,"metadata":{"id":"Hhnxz3SlWj9D","executionInfo":{"status":"ok","timestamp":1657026099528,"user_tz":-480,"elapsed":8,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"id":"Hhnxz3SlWj9D"},{"cell_type":"code","execution_count":8,"metadata":{"id":"Z3cVVC1PWmDd","executionInfo":{"status":"ok","timestamp":1657026108765,"user_tz":-480,"elapsed":9245,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["model = AlexNet().to(device)"],"id":"Z3cVVC1PWmDd"},{"cell_type":"code","execution_count":10,"metadata":{"id":"rKL2sWm3gTkc","executionInfo":{"status":"ok","timestamp":1657026136540,"user_tz":-480,"elapsed":2,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[],"source":["loss_fn = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.5)"],"id":"rKL2sWm3gTkc"},{"cell_type":"code","source":["from sklearn.metrics import log_loss\n","from sklearn.model_selection import KFold as kFold"],"metadata":{"id":"7aDDVGIIdBCQ","executionInfo":{"status":"ok","timestamp":1657026135576,"user_tz":-480,"elapsed":2019,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"id":"7aDDVGIIdBCQ","execution_count":9,"outputs":[]},{"cell_type":"code","source":["x_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/train_1channel.npy\")\n","y_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/label.npy\")"],"metadata":{"id":"KX9ycWvMdAqD","executionInfo":{"status":"ok","timestamp":1657026170211,"user_tz":-480,"elapsed":21093,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"id":"KX9ycWvMdAqD","execution_count":11,"outputs":[]},{"cell_type":"code","source":["kfold =kFold(n_splits=5,shuffle=True,random_state=1)"],"metadata":{"id":"VOU_JGT4dAKg","executionInfo":{"status":"ok","timestamp":1657026170211,"user_tz":-480,"elapsed":6,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"id":"VOU_JGT4dAKg","execution_count":12,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, data,label):\n","        self.data = data #加载npy数据\n","        self.label = label\n","        self.transforms = transform #转为tensor形式\n","    def __getitem__(self, index):\n","        hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","        hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","        hdct= self.transforms(hdct)  #转为tensor形式\n","#         ldct= self.transforms(ldct)  #转为tensor形式\n","        return hdct, self.label[index] #返回数据还有标签\n","    def __len__(self):\n","        return self.data.shape[0] #返回数据的总个数"],"metadata":{"id":"GpJgpJbSdGna","executionInfo":{"status":"ok","timestamp":1657026172922,"user_tz":-480,"elapsed":4,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"id":"GpJgpJbSdGna","execution_count":13,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JvHV9TEdJ-W","executionInfo":{"status":"ok","timestamp":1657026172922,"user_tz":-480,"elapsed":3,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}},"outputId":"d172a936-31c8-4651-e543-b6d8ba4c3a94"},"id":"_JvHV9TEdJ-W","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AlexNet(\n","  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (features): Sequential(\n","    (0): Conv2d(1, 24, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1152, out_features=128, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=128, out_features=64, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=64, out_features=8, bias=True)\n","  )\n","  (logsoftmax): LogSoftmax(dim=1)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["labels=[0,1,2,3,4,5,6,7]\n","list_score=[]\n","for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","    print(\"train_index\",train_index)\n","    print(\"test_index\",test_index)\n","    ### Dividing data into folds\n","    x_train_fold = x_train[train_index]\n","    x_test_fold = x_train[test_index]\n","    y_train_fold = y_train[train_index]\n","    y_test_fold = y_train[test_index]\n","    train = MyDataset(x_train_fold, y_train_fold)\n","    test = MyDataset(x_test_fold, y_test_fold)\n","    train_loader = DataLoader(train, batch_size = 8, shuffle = True)\n","    test_loader = DataLoader(test, batch_size = 8, shuffle = False)\n","    print(\"fold:\",fold)\n","    max_score=[]\n","    # model = Net().to(device)\n","    best_acc=0\n","    model = AlexNet().to(device)\n","    loss_fn = nn.NLLLoss()\n","    optimizer = torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.5)\n","    for i in range(50):\n","      list1=[]\n","      for t, (data, target) in enumerate(train_loader):\n","        # print(\"t\",t)\n","        data,target = Variable(data.to(device)),Variable(target.to(device))\n","        # print(data.shape)\n","        pred = model(data.double().to(device))\n","        loss = loss_fn(pred,target)\n","        \n","        list1.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # print(\"loss\",loss.item())\n","      print(\"netloss\",i,np.mean(list1))\n","      with torch.no_grad():\n","        list_loss=[]\n","        correct = 0\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data.double().to(device))\n","            # get the index of the max log-probability\n","            pred = output.data.max(1, keepdim=True)[1]\n","            pred_loss=np.exp(output.data.cpu())\n","            logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","            list_loss.append(logsloss)\n","            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","        print('accuracy:{:.3f}%'.format(\n","            100. * correct / len(test_loader.dataset)))\n","        val_acc=correct / len(test_loader.dataset)\n","        print(\"log_loss\",sum(list_loss)/len(list_loss))\n","        print(\"*\"*20)\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            es = 0\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            if es > 5:\n","                print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","                break\n","    list_score.append(best_acc)\n","    print(\"*\"*40)\n","from numpy import mean\n","print(mean(list_score))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUBi2PYJXcmS","outputId":"8c6ddee9-7e7e-4108-9bf7-a22b64a91cc9","executionInfo":{"status":"ok","timestamp":1657038168210,"user_tz":-480,"elapsed":11949649,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"id":"fUBi2PYJXcmS","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["train_index [    0     1     2 ... 13884 13885 13886]\n","test_index [    4     5     6 ... 13861 13872 13877]\n","fold: 0\n","netloss 0 1.6116279547537191\n","accuracy:49.928%\n","log_loss 1.4344277491680884\n","********************\n","netloss 1 1.4018267088328957\n","accuracy:53.672%\n","log_loss 1.3379934492443901\n","********************\n","netloss 2 1.321562856750203\n","accuracy:53.960%\n","log_loss 1.3168480626894452\n","********************\n","netloss 3 1.1944954784788557\n","accuracy:62.815%\n","log_loss 1.0816675777413012\n","********************\n","netloss 4 1.0635519200807098\n","accuracy:58.819%\n","log_loss 1.1791515607634981\n","********************\n","Counter 1 of 5\n","netloss 5 0.9982294530859179\n","accuracy:67.027%\n","log_loss 0.9629423567871354\n","********************\n","netloss 6 0.9222999396898351\n","accuracy:70.374%\n","log_loss 0.8694760607085915\n","********************\n","netloss 7 0.8389783863066401\n","accuracy:72.750%\n","log_loss 0.8293055031681597\n","********************\n","netloss 8 0.7979960666361896\n","accuracy:76.998%\n","log_loss 0.714267367740224\n","********************\n","netloss 9 0.7496083026123942\n","accuracy:77.214%\n","log_loss 0.7172636409323049\n","********************\n","netloss 10 0.7155606462470809\n","accuracy:78.942%\n","log_loss 0.6651661692531444\n","********************\n","netloss 11 0.6665538994875077\n","accuracy:79.266%\n","log_loss 0.647269339891105\n","********************\n","netloss 12 0.6583427902145659\n","accuracy:79.662%\n","log_loss 0.6501497826493269\n","********************\n","netloss 13 0.6198271453361138\n","accuracy:80.742%\n","log_loss 0.6072296372370245\n","********************\n","netloss 14 0.6099942063362607\n","accuracy:80.778%\n","log_loss 0.5965346450199497\n","********************\n","netloss 15 0.5991241900363823\n","accuracy:80.922%\n","log_loss 0.5932043532887906\n","********************\n","netloss 16 0.5795157053486479\n","accuracy:81.102%\n","log_loss 0.5863556116536078\n","********************\n","netloss 17 0.5514108623594428\n","accuracy:82.649%\n","log_loss 0.58479272559643\n","********************\n","netloss 18 0.540585793246383\n","accuracy:82.721%\n","log_loss 0.562484532563252\n","********************\n","netloss 19 0.527797317888803\n","accuracy:82.901%\n","log_loss 0.5550909301790903\n","********************\n","netloss 20 0.5153111255815754\n","accuracy:82.325%\n","log_loss 0.550888228779322\n","********************\n","Counter 1 of 5\n","netloss 21 0.49593352440173133\n","accuracy:83.549%\n","log_loss 0.5249959877283221\n","********************\n","netloss 22 0.4991237610343626\n","accuracy:83.189%\n","log_loss 0.5433304527187794\n","********************\n","Counter 1 of 5\n","netloss 23 0.48286348885123853\n","accuracy:83.333%\n","log_loss 0.5375209032696114\n","********************\n","Counter 2 of 5\n","netloss 24 0.4767469968123988\n","accuracy:83.513%\n","log_loss 0.5277521589736375\n","********************\n","Counter 3 of 5\n","netloss 25 0.47736362437389307\n","accuracy:83.441%\n","log_loss 0.5416448667094516\n","********************\n","Counter 4 of 5\n","netloss 26 0.4619557163583189\n","accuracy:82.649%\n","log_loss 0.5502597700838529\n","********************\n","Counter 5 of 5\n","netloss 27 0.45214266027201594\n","accuracy:82.973%\n","log_loss 0.566280579762443\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8355) and val_acc for this epoch:  tensor(0.8297) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13885]\n","test_index [   16    21    24 ... 13866 13867 13886]\n","fold: 1\n","netloss 0 1.5807514663440427\n","accuracy:48.236%\n","log_loss 1.4450091312674207\n","********************\n","netloss 1 1.3692390533451986\n","accuracy:51.872%\n","log_loss 1.294116854933349\n","********************\n","netloss 2 1.2441126135864389\n","accuracy:56.983%\n","log_loss 1.1799509695106636\n","********************\n","netloss 3 1.1110491549519013\n","accuracy:63.427%\n","log_loss 1.0458304444807367\n","********************\n","netloss 4 0.9828254782209673\n","accuracy:66.523%\n","log_loss 0.9542604298677674\n","********************\n","netloss 5 0.901271004802302\n","accuracy:71.742%\n","log_loss 0.8683430958804105\n","********************\n","netloss 6 0.8478850003973389\n","accuracy:71.922%\n","log_loss 0.8441594648848518\n","********************\n","netloss 7 0.8026412092944126\n","accuracy:73.290%\n","log_loss 0.7798989348861209\n","********************\n","netloss 8 0.7496335799943475\n","accuracy:75.414%\n","log_loss 0.7557679415141677\n","********************\n","netloss 9 0.7155882752245338\n","accuracy:76.422%\n","log_loss 0.7197375567865237\n","********************\n","netloss 10 0.6747187662132804\n","accuracy:76.746%\n","log_loss 0.7060425222246587\n","********************\n","netloss 11 0.6831579691241235\n","accuracy:78.222%\n","log_loss 0.6679593566614356\n","********************\n","netloss 12 0.658126387545241\n","accuracy:78.546%\n","log_loss 0.6432807035654183\n","********************\n","netloss 13 0.6215743421626557\n","accuracy:80.670%\n","log_loss 0.6086456489410665\n","********************\n","netloss 14 0.6129723862776176\n","accuracy:79.626%\n","log_loss 0.6177751529869855\n","********************\n","Counter 1 of 5\n","netloss 15 0.5919336984271787\n","accuracy:79.374%\n","log_loss 0.6316505374528772\n","********************\n","Counter 2 of 5\n","netloss 16 0.5801490625625955\n","accuracy:81.425%\n","log_loss 0.5843831008409583\n","********************\n","netloss 17 0.5751430138202042\n","accuracy:80.346%\n","log_loss 0.6292310300410215\n","********************\n","Counter 1 of 5\n","netloss 18 0.5671421921490046\n","accuracy:80.886%\n","log_loss 0.5953631227304493\n","********************\n","Counter 2 of 5\n","netloss 19 0.5423820605134915\n","accuracy:79.554%\n","log_loss 0.6126313159316914\n","********************\n","Counter 3 of 5\n","netloss 20 0.5184841023462139\n","accuracy:81.461%\n","log_loss 0.5657230954275145\n","********************\n","netloss 21 0.515983982078539\n","accuracy:81.138%\n","log_loss 0.5740519606533895\n","********************\n","Counter 1 of 5\n","netloss 22 0.5031780113774308\n","accuracy:81.785%\n","log_loss 0.5666787874466006\n","********************\n","netloss 23 0.4899356284625635\n","accuracy:82.361%\n","log_loss 0.574326907852302\n","********************\n","netloss 24 0.4984385879133291\n","accuracy:82.793%\n","log_loss 0.545289419368332\n","********************\n","netloss 25 0.4747397475775966\n","accuracy:83.657%\n","log_loss 0.5291426586515382\n","********************\n","netloss 26 0.46712533354506014\n","accuracy:82.793%\n","log_loss 0.5339997050446937\n","********************\n","Counter 1 of 5\n","netloss 27 0.44994731762757545\n","accuracy:82.649%\n","log_loss 0.5610073854629388\n","********************\n","Counter 2 of 5\n","netloss 28 0.4531137433029701\n","accuracy:82.109%\n","log_loss 0.5552869274924159\n","********************\n","Counter 3 of 5\n","netloss 29 0.4440821451761115\n","accuracy:83.297%\n","log_loss 0.555543768426783\n","********************\n","Counter 4 of 5\n","netloss 30 0.4346348991500461\n","accuracy:84.125%\n","log_loss 0.5186448186698571\n","********************\n","netloss 31 0.43695373579436486\n","accuracy:84.737%\n","log_loss 0.5243334431552864\n","********************\n","netloss 32 0.421508842208319\n","accuracy:83.621%\n","log_loss 0.5275493086606788\n","********************\n","Counter 1 of 5\n","netloss 33 0.4185157437165474\n","accuracy:83.585%\n","log_loss 0.5221199480956894\n","********************\n","Counter 2 of 5\n","netloss 34 0.40993464415049496\n","accuracy:84.737%\n","log_loss 0.5079276813059418\n","********************\n","Counter 3 of 5\n","netloss 35 0.39398082288483244\n","accuracy:84.449%\n","log_loss 0.521981947332338\n","********************\n","Counter 4 of 5\n","netloss 36 0.3971201376054623\n","accuracy:85.205%\n","log_loss 0.5082037901097327\n","********************\n","netloss 37 0.3822644962087084\n","accuracy:84.485%\n","log_loss 0.5183433251159154\n","********************\n","Counter 1 of 5\n","netloss 38 0.3816166925851637\n","accuracy:84.881%\n","log_loss 0.5005889191145987\n","********************\n","Counter 2 of 5\n","netloss 39 0.3906429498178291\n","accuracy:84.197%\n","log_loss 0.527261232507762\n","********************\n","Counter 3 of 5\n","netloss 40 0.3727852616780823\n","accuracy:85.097%\n","log_loss 0.508903908226506\n","********************\n","Counter 4 of 5\n","netloss 41 0.366557289447312\n","accuracy:85.277%\n","log_loss 0.5044631797979073\n","********************\n","netloss 42 0.3680824810603727\n","accuracy:84.557%\n","log_loss 0.518130925862661\n","********************\n","Counter 1 of 5\n","netloss 43 0.36821557470413807\n","accuracy:85.313%\n","log_loss 0.4961541826496452\n","********************\n","netloss 44 0.34779715053457205\n","accuracy:85.457%\n","log_loss 0.4997704892764591\n","********************\n","netloss 45 0.34867678871801505\n","accuracy:85.529%\n","log_loss 0.5090134749180193\n","********************\n","netloss 46 0.35311878792969237\n","accuracy:84.773%\n","log_loss 0.5175632781520558\n","********************\n","Counter 1 of 5\n","netloss 47 0.36961293922082533\n","accuracy:85.961%\n","log_loss 0.5084299676893173\n","********************\n","netloss 48 0.3431071225885239\n","accuracy:85.997%\n","log_loss 0.5001950594879427\n","********************\n","netloss 49 0.3416311492088704\n","accuracy:85.781%\n","log_loss 0.482221900784454\n","********************\n","Counter 1 of 5\n","****************************************\n","train_index [    0     2     4 ... 13884 13885 13886]\n","test_index [    1     3    10 ... 13880 13881 13883]\n","fold: 2\n","netloss 0 1.6018941739967012\n","accuracy:48.254%\n","log_loss 1.4863136947787778\n","********************\n","netloss 1 1.38169711893908\n","accuracy:51.566%\n","log_loss 1.3593701955839608\n","********************\n","netloss 2 1.256899841940444\n","accuracy:56.140%\n","log_loss 1.2126476997864217\n","********************\n","netloss 3 1.1112166031738233\n","accuracy:63.450%\n","log_loss 1.0891710595901112\n","********************\n","netloss 4 1.2962976053598227\n","accuracy:55.492%\n","log_loss 1.3205255535413645\n","********************\n","Counter 1 of 5\n","netloss 5 1.2608149957728345\n","accuracy:58.408%\n","log_loss 1.1965492603537091\n","********************\n","Counter 2 of 5\n","netloss 6 1.122160485899842\n","accuracy:64.422%\n","log_loss 1.0235803455134873\n","********************\n","netloss 7 1.03839602552015\n","accuracy:68.635%\n","log_loss 0.9566317930397942\n","********************\n","netloss 8 0.9300605613442314\n","accuracy:71.372%\n","log_loss 0.8993159397364837\n","********************\n","netloss 9 0.866058957437236\n","accuracy:72.668%\n","log_loss 0.8496977911480319\n","********************\n","netloss 10 0.8286899043867473\n","accuracy:74.505%\n","log_loss 0.7936290841597015\n","********************\n","netloss 11 0.779770921313066\n","accuracy:74.793%\n","log_loss 0.7984120576344377\n","********************\n","netloss 12 0.7356699338494924\n","accuracy:75.297%\n","log_loss 0.7648887007101148\n","********************\n","netloss 13 0.7088046801558636\n","accuracy:76.485%\n","log_loss 0.7356641179632681\n","********************\n","netloss 14 0.6966875904232537\n","accuracy:78.646%\n","log_loss 0.6975962399268215\n","********************\n","netloss 15 0.658061131921659\n","accuracy:79.726%\n","log_loss 0.6603205399869474\n","********************\n","netloss 16 0.6552265945188218\n","accuracy:79.690%\n","log_loss 0.6539764061210734\n","********************\n","Counter 1 of 5\n","netloss 17 0.6270180075849588\n","accuracy:80.447%\n","log_loss 0.6432253106080618\n","********************\n","netloss 18 0.6130741719371953\n","accuracy:81.203%\n","log_loss 0.5998465865336486\n","********************\n","netloss 19 0.5861760316225471\n","accuracy:81.635%\n","log_loss 0.6171466760397928\n","********************\n","netloss 20 0.5687120893654753\n","accuracy:81.455%\n","log_loss 0.6021750093530451\n","********************\n","Counter 1 of 5\n","netloss 21 0.5553971423662422\n","accuracy:81.527%\n","log_loss 0.5971692773016899\n","********************\n","Counter 2 of 5\n","netloss 22 0.5354065199535081\n","accuracy:82.895%\n","log_loss 0.5909053461714427\n","********************\n","netloss 23 0.5980666454832448\n","accuracy:77.998%\n","log_loss 0.6875817941680518\n","********************\n","Counter 1 of 5\n","netloss 24 0.5829274554843455\n","accuracy:81.887%\n","log_loss 0.5873433192817454\n","********************\n","Counter 2 of 5\n","netloss 25 0.5253523589484089\n","accuracy:82.355%\n","log_loss 0.5620706227140163\n","********************\n","Counter 3 of 5\n","netloss 26 0.5121695953090881\n","accuracy:82.823%\n","log_loss 0.5661318230238778\n","********************\n","Counter 4 of 5\n","netloss 27 0.4828370576008436\n","accuracy:83.111%\n","log_loss 0.5582001461229528\n","********************\n","netloss 28 0.48553449175175634\n","accuracy:82.427%\n","log_loss 0.5712528156009583\n","********************\n","Counter 1 of 5\n","netloss 29 0.47310995345565815\n","accuracy:83.651%\n","log_loss 0.5486680340802117\n","********************\n","netloss 30 0.45698614709795177\n","accuracy:83.507%\n","log_loss 0.5478963326778653\n","********************\n","Counter 1 of 5\n","netloss 31 0.4529486448304825\n","accuracy:83.795%\n","log_loss 0.5566515522834328\n","********************\n","netloss 32 0.4469516617815675\n","accuracy:84.552%\n","log_loss 0.5205867564087615\n","********************\n","netloss 33 0.4379501984925675\n","accuracy:83.795%\n","log_loss 0.5419072846576799\n","********************\n","Counter 1 of 5\n","netloss 34 0.4307727069224077\n","accuracy:83.723%\n","log_loss 0.5489274384151399\n","********************\n","Counter 2 of 5\n","netloss 35 0.42212724528852397\n","accuracy:84.264%\n","log_loss 0.5352251399650166\n","********************\n","Counter 3 of 5\n","netloss 36 0.4173772640377845\n","accuracy:82.931%\n","log_loss 0.5768675702290972\n","********************\n","Counter 4 of 5\n","netloss 37 0.4152783741680785\n","accuracy:84.480%\n","log_loss 0.5172638420977911\n","********************\n","Counter 5 of 5\n","netloss 38 0.4151807812095934\n","accuracy:84.480%\n","log_loss 0.5146928820000359\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8455) and val_acc for this epoch:  tensor(0.8448) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13886]\n","test_index [    8     9    13 ... 13876 13882 13885]\n","fold: 3\n","netloss 0 1.5923299030024987\n","accuracy:48.001%\n","log_loss 1.5003328332399466\n","********************\n","netloss 1 1.4385524134331964\n","accuracy:48.974%\n","log_loss 1.389604732684486\n","********************\n","netloss 2 1.3172961207489353\n","accuracy:52.323%\n","log_loss 1.3229903718416487\n","********************\n","netloss 3 1.2099032419967382\n","accuracy:60.137%\n","log_loss 1.16504536258822\n","********************\n","netloss 4 1.066239769494081\n","accuracy:61.613%\n","log_loss 1.0921990602113587\n","********************\n","netloss 5 0.9987540584075125\n","accuracy:66.259%\n","log_loss 1.0029903599629304\n","********************\n","netloss 6 0.9099270021580956\n","accuracy:69.319%\n","log_loss 0.920849419564433\n","********************\n","netloss 7 0.8395107316168535\n","accuracy:71.228%\n","log_loss 0.8783869230650166\n","********************\n","netloss 8 0.7817078125824027\n","accuracy:72.920%\n","log_loss 0.8358294034760908\n","********************\n","netloss 9 0.7609664425365273\n","accuracy:74.073%\n","log_loss 0.8109445002777341\n","********************\n","netloss 10 0.7117467649239203\n","accuracy:74.181%\n","log_loss 0.7832595259155992\n","********************\n","netloss 11 0.716267185860007\n","accuracy:74.469%\n","log_loss 0.7549627865263387\n","********************\n","netloss 12 0.6660285364704132\n","accuracy:77.782%\n","log_loss 0.7508323253866819\n","********************\n","netloss 13 0.6468211254133285\n","accuracy:75.477%\n","log_loss 0.7870456066786403\n","********************\n","Counter 1 of 5\n","netloss 14 0.620462212470383\n","accuracy:76.377%\n","log_loss 0.7221997179369193\n","********************\n","Counter 2 of 5\n","netloss 15 0.6030108084103043\n","accuracy:77.710%\n","log_loss 0.7023553767137526\n","********************\n","Counter 3 of 5\n","netloss 16 0.5893491121245329\n","accuracy:78.430%\n","log_loss 0.6862330399834342\n","********************\n","netloss 17 0.5725602461208245\n","accuracy:77.422%\n","log_loss 0.7125906649683461\n","********************\n","Counter 1 of 5\n","netloss 18 0.5762782480413526\n","accuracy:80.194%\n","log_loss 0.6869935642006758\n","********************\n","netloss 19 0.5435481383949278\n","accuracy:80.086%\n","log_loss 0.6735380027109839\n","********************\n","Counter 1 of 5\n","netloss 20 0.5340738724987907\n","accuracy:80.771%\n","log_loss 0.627005041291231\n","********************\n","netloss 21 0.5329924431841747\n","accuracy:80.302%\n","log_loss 0.6543361397228754\n","********************\n","Counter 1 of 5\n","netloss 22 0.5256703712586406\n","accuracy:80.519%\n","log_loss 0.6376824670590964\n","********************\n","Counter 2 of 5\n","netloss 23 0.5066432345495614\n","accuracy:79.186%\n","log_loss 0.6834871276229422\n","********************\n","Counter 3 of 5\n","netloss 24 0.5103381265036172\n","accuracy:80.050%\n","log_loss 0.6644165018907031\n","********************\n","Counter 4 of 5\n","netloss 25 0.48508101066566034\n","accuracy:81.095%\n","log_loss 0.612082241452727\n","********************\n","netloss 26 0.4897877022506488\n","accuracy:81.599%\n","log_loss 0.609008850061231\n","********************\n","netloss 27 0.46198837527608483\n","accuracy:80.663%\n","log_loss 0.6137757098417191\n","********************\n","Counter 1 of 5\n","netloss 28 0.4607121431424349\n","accuracy:81.023%\n","log_loss 0.584948045183217\n","********************\n","Counter 2 of 5\n","netloss 29 0.449572811677854\n","accuracy:81.563%\n","log_loss 0.6346077574040235\n","********************\n","Counter 3 of 5\n","netloss 30 0.4403477080806763\n","accuracy:82.067%\n","log_loss 0.5930785000804415\n","********************\n","netloss 31 0.4356534738441319\n","accuracy:81.707%\n","log_loss 0.6145470365077137\n","********************\n","Counter 1 of 5\n","netloss 32 0.44086804978242766\n","accuracy:82.067%\n","log_loss 0.6062322936747505\n","********************\n","Counter 2 of 5\n","netloss 33 0.42353395734281224\n","accuracy:82.319%\n","log_loss 0.576161040763089\n","********************\n","netloss 34 0.416463148791212\n","accuracy:82.427%\n","log_loss 0.6010385666449563\n","********************\n","netloss 35 0.39617146083948057\n","accuracy:82.787%\n","log_loss 0.5954426532488363\n","********************\n","netloss 36 0.4050574604167235\n","accuracy:82.319%\n","log_loss 0.6088119718914247\n","********************\n","Counter 1 of 5\n","netloss 37 0.3922160703034909\n","accuracy:82.355%\n","log_loss 0.5652114415942681\n","********************\n","Counter 2 of 5\n","netloss 38 0.40764485118423655\n","accuracy:82.391%\n","log_loss 0.5812591108469186\n","********************\n","Counter 3 of 5\n","netloss 39 0.4010563449916487\n","accuracy:82.715%\n","log_loss 0.5783416344324476\n","********************\n","Counter 4 of 5\n","netloss 40 0.3869280937526403\n","accuracy:83.327%\n","log_loss 0.5613714457205661\n","********************\n","netloss 41 0.3888306545761622\n","accuracy:83.795%\n","log_loss 0.5688587974479626\n","********************\n","netloss 42 0.37848049821715574\n","accuracy:83.831%\n","log_loss 0.5522158544018747\n","********************\n","netloss 43 0.3751259885567837\n","accuracy:83.039%\n","log_loss 0.5961987381349801\n","********************\n","Counter 1 of 5\n","netloss 44 0.3691224938610436\n","accuracy:83.976%\n","log_loss 0.5373689662000036\n","********************\n","netloss 45 0.38813224329553503\n","accuracy:83.507%\n","log_loss 0.5905484449002403\n","********************\n","Counter 1 of 5\n","netloss 46 0.3629307990935849\n","accuracy:83.075%\n","log_loss 0.563404846996431\n","********************\n","Counter 2 of 5\n","netloss 47 0.3531332226870605\n","accuracy:83.363%\n","log_loss 0.5784645830594461\n","********************\n","Counter 3 of 5\n","netloss 48 0.3552710381123345\n","accuracy:83.219%\n","log_loss 0.5716241781968493\n","********************\n","Counter 4 of 5\n","netloss 49 0.33961202941809304\n","accuracy:83.435%\n","log_loss 0.5678474381188334\n","********************\n","Counter 5 of 5\n","****************************************\n","train_index [    1     3     4 ... 13883 13885 13886]\n","test_index [    0     2    15 ... 13868 13879 13884]\n","fold: 4\n","netloss 0 1.5847488854191307\n","accuracy:49.802%\n","log_loss 1.430408635359278\n","********************\n","netloss 1 1.3851209954333574\n","accuracy:53.979%\n","log_loss 1.3090968340608706\n","********************\n","netloss 2 1.360891157063913\n","accuracy:54.699%\n","log_loss 1.272354649295902\n","********************\n","netloss 3 1.2520885597121991\n","accuracy:58.876%\n","log_loss 1.1700497426901688\n","********************\n","netloss 4 1.1616822879997217\n","accuracy:61.973%\n","log_loss 1.1044115219733752\n","********************\n","netloss 5 1.1276491850804873\n","accuracy:63.270%\n","log_loss 1.076092947346887\n","********************\n","netloss 6 1.0474826228327414\n","accuracy:65.394%\n","log_loss 0.9835394802293831\n","********************\n","netloss 7 0.9603431600648792\n","accuracy:66.943%\n","log_loss 0.9508131900066175\n","********************\n","netloss 8 0.9121131991315512\n","accuracy:66.403%\n","log_loss 1.0109752574003221\n","********************\n","Counter 1 of 5\n","netloss 9 0.8500847283614749\n","accuracy:71.696%\n","log_loss 0.8372058960153793\n","********************\n","netloss 10 0.7877769084763525\n","accuracy:74.829%\n","log_loss 0.7713243358485933\n","********************\n","netloss 11 0.7508488521216781\n","accuracy:76.269%\n","log_loss 0.7080291322350761\n","********************\n","netloss 12 0.7222357340488422\n","accuracy:76.665%\n","log_loss 0.7158424582458007\n","********************\n","netloss 13 0.7049723926690729\n","accuracy:76.629%\n","log_loss 0.7281212332369715\n","********************\n","Counter 1 of 5\n","netloss 14 0.6772972508441842\n","accuracy:76.377%\n","log_loss 0.717055646281865\n","********************\n","Counter 2 of 5\n","netloss 15 0.6483806963918364\n","accuracy:77.026%\n","log_loss 0.6798869649131514\n","********************\n","netloss 16 0.6363384362032038\n","accuracy:80.194%\n","log_loss 0.6230353856659235\n","********************\n","netloss 17 0.6192566467698342\n","accuracy:79.258%\n","log_loss 0.6455551257215659\n","********************\n","Counter 1 of 5\n","netloss 18 0.6076013093130449\n","accuracy:79.438%\n","log_loss 0.635196458834606\n","********************\n","Counter 2 of 5\n","netloss 19 0.5878805312867519\n","accuracy:79.654%\n","log_loss 0.634099775318109\n","********************\n","Counter 3 of 5\n","netloss 20 0.5812696374946593\n","accuracy:80.266%\n","log_loss 0.6068514134949037\n","********************\n","netloss 21 0.6003046146349317\n","accuracy:81.095%\n","log_loss 0.5924528085054487\n","********************\n","netloss 22 0.5616707993857508\n","accuracy:81.023%\n","log_loss 0.5983610879113093\n","********************\n","Counter 1 of 5\n","netloss 23 0.5417645361441253\n","accuracy:81.131%\n","log_loss 0.5874199180778149\n","********************\n","netloss 24 0.5183305225844672\n","accuracy:81.095%\n","log_loss 0.5853132335581861\n","********************\n","Counter 1 of 5\n","netloss 25 0.5217399947226815\n","accuracy:81.455%\n","log_loss 0.5897013069473732\n","********************\n","netloss 26 0.5291008020660611\n","accuracy:82.355%\n","log_loss 0.547865558667733\n","********************\n","netloss 27 0.5025731016346574\n","accuracy:81.743%\n","log_loss 0.5537108965761905\n","********************\n","Counter 1 of 5\n","netloss 28 0.48845188080370217\n","accuracy:82.427%\n","log_loss 0.5458321774495636\n","********************\n","netloss 29 0.49508804194864575\n","accuracy:82.247%\n","log_loss 0.5483992639685676\n","********************\n","Counter 1 of 5\n","netloss 30 0.4706781199458268\n","accuracy:82.427%\n","log_loss 0.5447947770795619\n","********************\n","Counter 2 of 5\n","netloss 31 0.45951467284754627\n","accuracy:82.355%\n","log_loss 0.5612130211264725\n","********************\n","Counter 3 of 5\n","netloss 32 0.4584085182620785\n","accuracy:83.399%\n","log_loss 0.5381393904887055\n","********************\n","netloss 33 0.4475570642601039\n","accuracy:83.003%\n","log_loss 0.5210487784009485\n","********************\n","Counter 1 of 5\n","netloss 34 0.441262790942736\n","accuracy:83.219%\n","log_loss 0.5267225051202674\n","********************\n","Counter 2 of 5\n","netloss 35 0.4630765807200118\n","accuracy:82.787%\n","log_loss 0.5306757465104016\n","********************\n","Counter 3 of 5\n","netloss 36 0.4443727977999029\n","accuracy:82.931%\n","log_loss 0.5162241325283289\n","********************\n","Counter 4 of 5\n","netloss 37 0.4313123696003018\n","accuracy:83.723%\n","log_loss 0.5162934692469078\n","********************\n","netloss 38 0.4283595720710095\n","accuracy:82.931%\n","log_loss 0.5259209763754561\n","********************\n","Counter 1 of 5\n","netloss 39 0.4168376260039262\n","accuracy:83.903%\n","log_loss 0.5130058472396268\n","********************\n","netloss 40 0.4257209487765757\n","accuracy:84.768%\n","log_loss 0.5087772755911113\n","********************\n","netloss 41 0.4213172360219687\n","accuracy:83.940%\n","log_loss 0.5288236143966641\n","********************\n","Counter 1 of 5\n","netloss 42 0.39780495176977154\n","accuracy:84.084%\n","log_loss 0.5041888231362952\n","********************\n","Counter 2 of 5\n","netloss 43 0.39980453431716917\n","accuracy:83.075%\n","log_loss 0.5317058547199294\n","********************\n","Counter 3 of 5\n","netloss 44 0.3917152924355252\n","accuracy:85.020%\n","log_loss 0.508013796298132\n","********************\n","netloss 45 0.3912298394065519\n","accuracy:84.264%\n","log_loss 0.5027878180821201\n","********************\n","Counter 1 of 5\n","netloss 46 0.3866647476531615\n","accuracy:84.264%\n","log_loss 0.50464172540521\n","********************\n","Counter 2 of 5\n","netloss 47 0.3754572198140618\n","accuracy:83.867%\n","log_loss 0.5250831572073817\n","********************\n","Counter 3 of 5\n","netloss 48 0.37334255254288007\n","accuracy:84.444%\n","log_loss 0.5154526157914731\n","********************\n","Counter 4 of 5\n","netloss 49 0.3815138868781997\n","accuracy:83.940%\n","log_loss 0.5206999086801584\n","********************\n","Counter 5 of 5\n","****************************************\n","0.846186858886363\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":" alexnet1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}