{"cells":[{"cell_type":"markdown","metadata":{"id":"3BnbRO7ugk2Z"},"source":["# 代码要求：使用五倍交叉，训练100轮，使用早停技术"],"id":"3BnbRO7ugk2Z"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67093,"status":"ok","timestamp":1657069319150,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"idQkTJZDejiP","outputId":"ef8810c7-1d8d-48d0-ad65-2e6b153e69ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"idQkTJZDejiP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd0e5ef3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"],"id":"bd0e5ef3"},{"cell_type":"markdown","metadata":{"id":"SHuCCF5Bgorp"},"source":["# test"],"id":"SHuCCF5Bgorp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSTWoAm8fIat"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import torch.nn as nn\n","from torchvision import datasets,transforms\n","from torch.autograd import Variable"],"id":"hSTWoAm8fIat"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVC3JbajfP1L"},"outputs":[],"source":["import torch\n","import numpy as np\n","import skimage\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","torch.manual_seed(1)  # reproducible\n","torch.set_default_tensor_type(torch.DoubleTensor)\n","from PIL import Image\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n","])"],"id":"QVC3JbajfP1L"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2780,"status":"ok","timestamp":1657069325203,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"X37_O0J1GChl","outputId":"15f97907-c0e5-426e-a685-c575cdcbfc9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-2.2058, -2.1214, -2.1306, -2.3809, -2.2629, -1.9754, -2.0439, -1.6795],\n","        [-2.1892, -2.0654, -2.0936, -2.4782, -2.1737, -1.9401, -2.0993, -1.7481],\n","        [-2.2729, -2.0918, -2.0801, -2.4192, -2.1380, -1.9708, -2.1069, -1.7106],\n","        [-2.2124, -2.1238, -2.0239, -2.5300, -2.1695, -1.9616, -2.0067, -1.7726],\n","        [-2.1401, -2.0832, -2.1495, -2.5172, -2.2200, -1.8659, -2.0799, -1.7586],\n","        [-2.1962, -2.1255, -2.0896, -2.5006, -2.1425, -1.8851, -2.0999, -1.7603],\n","        [-2.1087, -2.0685, -2.1195, -2.4481, -2.2855, -1.9910, -2.0723, -1.7065],\n","        [-2.1999, -2.0028, -2.1338, -2.3778, -2.1556, -2.0565, -2.1379, -1.7068],\n","        [-2.2501, -2.0171, -2.0931, -2.4526, -2.1304, -1.9699, -2.1309, -1.7418],\n","        [-2.1908, -2.0183, -2.1281, -2.4875, -2.2104, -2.0093, -2.0694, -1.6976],\n","        [-2.2652, -2.0057, -2.1764, -2.4577, -2.1135, -1.8766, -2.2022, -1.7256],\n","        [-2.2383, -2.0783, -2.1641, -2.4182, -2.0951, -1.9994, -2.0666, -1.7193],\n","        [-2.3554, -2.0406, -2.1546, -2.3760, -2.0593, -1.9584, -2.2082, -1.6724],\n","        [-2.1457, -2.0138, -2.2027, -2.5120, -2.1390, -2.0147, -2.1464, -1.6613],\n","        [-2.1220, -2.1067, -2.0536, -2.3643, -2.2103, -1.9420, -2.1860, -1.7671],\n","        [-2.2741, -1.9554, -2.1128, -2.4801, -2.1810, -1.9993, -2.0626, -1.7401],\n","        [-2.1465, -2.1264, -2.1352, -2.4886, -2.1549, -1.9363, -2.0341, -1.7624],\n","        [-2.1962, -2.0971, -2.0787, -2.4602, -2.1033, -1.9042, -2.1379, -1.7924],\n","        [-2.1834, -2.0750, -2.1733, -2.4345, -2.2420, -1.8467, -2.0894, -1.7569],\n","        [-2.3136, -2.0685, -2.1252, -2.4281, -2.2781, -1.8281, -2.0271, -1.7591],\n","        [-2.1738, -2.0731, -2.1297, -2.4259, -2.2369, -2.0195, -2.1115, -1.6470],\n","        [-2.1440, -2.1341, -2.1090, -2.3535, -2.2460, -1.8893, -2.1001, -1.7799],\n","        [-2.1807, -2.1330, -2.1560, -2.3507, -2.1393, -1.9826, -2.0789, -1.7319],\n","        [-2.2536, -2.0344, -2.1791, -2.5130, -2.1677, -1.9295, -2.0012, -1.7417],\n","        [-2.1756, -2.0926, -2.1541, -2.4269, -2.0920, -1.9766, -2.0627, -1.7738],\n","        [-2.2508, -2.0776, -2.1252, -2.4593, -2.1450, -1.9345, -2.0772, -1.7277],\n","        [-2.2380, -2.0169, -2.0316, -2.4638, -2.2148, -1.9662, -2.0371, -1.8052],\n","        [-2.2701, -2.0110, -2.1723, -2.3530, -2.2170, -1.9902, -2.0597, -1.7107],\n","        [-2.1501, -2.0404, -2.1495, -2.5243, -2.1869, -1.9467, -2.1305, -1.6977],\n","        [-2.1009, -2.1183, -2.1056, -2.4529, -2.1987, -1.9921, -2.1168, -1.7046],\n","        [-2.1366, -2.0852, -2.1832, -2.3625, -2.2526, -1.9436, -2.2004, -1.6517],\n","        [-2.1036, -2.1010, -2.1406, -2.4333, -2.1612, -1.9876, -2.0916, -1.7452]],\n","       grad_fn=<LogSoftmaxBackward0>)\n"]}],"source":["# -*- coding: UTF-8 -*-\n","\"\"\"\n","@FileName: MobileNetV1.py\n","@Description: Implement MobileNetV1\n","@Author: Ryuk\n","@CreateDate: 2019/12/9 13:35\n","@LastEditTime: 2019/12/9 13:35\n","@LastEditors: Please set LastEditors\n","@Version: v1.0\n","\"\"\"\n","\n","import time\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.autograd import Variable\n","\n","\n","class MobileNet(nn.Module):\n","    def __init__(self):\n","        super(MobileNet, self).__init__()\n","\n","        def conv_bn(inp, oup, stride):\n","            return nn.Sequential(\n","                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n","                nn.BatchNorm2d(oup),\n","                nn.ReLU(inplace=True))\n","\n","        def conv_dw(inp, oup, stride):\n","            return nn.Sequential(\n","                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n","                nn.BatchNorm2d(inp),\n","                nn.ReLU(inplace=True),\n","\n","                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","                nn.ReLU(inplace=True))\n","\n","        self.feature = nn.Sequential(\n","            conv_bn(1, 32, 2),\n","            conv_dw(32, 64, 1),\n","            conv_dw(64, 128, 2),\n","            conv_dw(128, 128, 1),\n","            conv_dw(128, 256, 2),\n","            conv_dw(256, 256, 1),\n","            conv_dw(256, 512, 2),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 1024, 2),\n","            conv_dw(1024, 1024, 1),\n","            nn.AvgPool2d(7) )\n","\n","        self.fc = nn.Linear(1024, 8)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","    def forward(self, x):\n","        x = self.feature(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return self.logsoftmax(x)\n","\n","\n","\n","def main():\n","    x = torch.randn(32, 1, 224, 224)\n","    net = MobileNet()\n","    print(net(x))\n","\n","\n","if __name__ == '__main__':\n","    main()"],"id":"X37_O0J1GChl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hhnxz3SlWj9D"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"id":"Hhnxz3SlWj9D"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3cVVC1PWmDd"},"outputs":[],"source":["model = MobileNet().to(device)"],"id":"Z3cVVC1PWmDd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKL2sWm3gTkc"},"outputs":[],"source":["loss_fn = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.006,momentum=0.5)"],"id":"rKL2sWm3gTkc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXH-bVYReCmV"},"outputs":[],"source":["from sklearn.metrics import log_loss\n","from sklearn.model_selection import KFold as kFold"],"id":"oXH-bVYReCmV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yiQSvWeeFB3"},"outputs":[],"source":["x_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/train_1channel.npy\")\n","y_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/label.npy\")"],"id":"3yiQSvWeeFB3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdnM4EZ0eHIB"},"outputs":[],"source":["kfold =kFold(n_splits=5,shuffle=True,random_state=1)"],"id":"AdnM4EZ0eHIB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMrpsH3SEjt2"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, data,label):\n","        self.data = data #加载npy数据\n","        self.label = label\n","        self.transforms = transform #转为tensor形式\n","    def __getitem__(self, index):\n","        hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","        hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","        hdct= self.transforms(hdct)  #转为tensor形式\n","#         ldct= self.transforms(ldct)  #转为tensor形式\n","        return hdct, self.label[index] #返回数据还有标签\n","    def __len__(self):\n","        return self.data.shape[0] #返回数据的总个数"],"id":"UMrpsH3SEjt2"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mxx3MA-eeOy-","outputId":"d124b9f6-0c7d-4909-d27f-cc3bc2486d11","executionInfo":{"status":"ok","timestamp":1657089326797,"user_tz":-480,"elapsed":1873431,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["train_index [    0     1     2 ... 13884 13885 13886]\n","test_index [    4     5     6 ... 13861 13872 13877]\n","fold: 0\n","netloss 0 1.468732850299196\n","accuracy:51.440%\n","log_loss 1.3203302751089807\n","********************\n","netloss 1 1.2428574934638008\n","accuracy:59.719%\n","log_loss 1.116474240850368\n","********************\n","netloss 2 1.0567160545476408\n","accuracy:67.999%\n","log_loss 0.9627563849430674\n","********************\n","netloss 3 0.8781487578625958\n","accuracy:74.406%\n","log_loss 0.7719035307396569\n","********************\n","netloss 4 0.7363873021263176\n","accuracy:77.502%\n","log_loss 0.6842610121748496\n","********************\n","netloss 5 0.6561851600198888\n","accuracy:80.850%\n","log_loss 0.6289280486346678\n","********************\n","netloss 6 0.5958634488487454\n","accuracy:80.706%\n","log_loss 0.6095235365110425\n","********************\n","Counter 1 of 5\n","netloss 7 0.5468204302034793\n","accuracy:82.325%\n","log_loss 0.5542596504455639\n","********************\n","netloss 8 0.5141552404505431\n","accuracy:82.937%\n","log_loss 0.5369335177470775\n","********************\n","netloss 9 0.4671395066954737\n","accuracy:83.405%\n","log_loss 0.5302506155718186\n","********************\n","netloss 10 0.44961110755164363\n","accuracy:83.693%\n","log_loss 0.5083971341406919\n","********************\n","netloss 11 0.43427247798099955\n","accuracy:84.701%\n","log_loss 0.47633377446241865\n","********************\n","netloss 12 0.40640592335396114\n","accuracy:85.817%\n","log_loss 0.4647482779236393\n","********************\n","netloss 13 0.38569286916656875\n","accuracy:85.637%\n","log_loss 0.46203087671222404\n","********************\n","Counter 1 of 5\n","netloss 14 0.3781899055684695\n","accuracy:84.593%\n","log_loss 0.4676919556429847\n","********************\n","Counter 2 of 5\n","netloss 15 0.35549801132554953\n","accuracy:86.753%\n","log_loss 0.456210662442159\n","********************\n","netloss 16 0.33422619846711876\n","accuracy:86.393%\n","log_loss 0.4418399229597846\n","********************\n","Counter 1 of 5\n","netloss 17 0.32648265477135024\n","accuracy:86.429%\n","log_loss 0.4386113464069283\n","********************\n","Counter 2 of 5\n","netloss 18 0.3108647826072497\n","accuracy:86.069%\n","log_loss 0.4461322139423686\n","********************\n","Counter 3 of 5\n","netloss 19 0.29371907308073064\n","accuracy:86.141%\n","log_loss 0.4521849183218638\n","********************\n","Counter 4 of 5\n","netloss 20 0.2858284857820661\n","accuracy:85.997%\n","log_loss 0.4563934448708355\n","********************\n","Counter 5 of 5\n","netloss 21 0.2776948799948993\n","accuracy:85.457%\n","log_loss 0.4608966373312847\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8675) and val_acc for this epoch:  tensor(0.8546) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13885]\n","test_index [   16    21    24 ... 13866 13867 13886]\n","fold: 1\n","netloss 0 1.4687041711096778\n","accuracy:47.192%\n","log_loss 1.366513285190426\n","********************\n","netloss 1 1.273879744239501\n","accuracy:55.472%\n","log_loss 1.1915611681697553\n","********************\n","netloss 2 1.1072192254962316\n","accuracy:63.427%\n","log_loss 1.0421475423680253\n","********************\n","netloss 3 0.9469155502815373\n","accuracy:71.850%\n","log_loss 0.8451537490414097\n","********************\n","netloss 4 0.8030384893664527\n","accuracy:76.350%\n","log_loss 0.7380270057115261\n","********************\n","netloss 5 0.703900847521272\n","accuracy:78.294%\n","log_loss 0.6817987406393702\n","********************\n","netloss 6 0.63758361792382\n","accuracy:81.353%\n","log_loss 0.6192633712728673\n","********************\n","netloss 7 0.591562486548307\n","accuracy:81.641%\n","log_loss 0.5763373823745354\n","********************\n","netloss 8 0.5402626949096541\n","accuracy:82.361%\n","log_loss 0.5647523726122082\n","********************\n","netloss 9 0.5080159628083161\n","accuracy:83.297%\n","log_loss 0.5397908882824858\n","********************\n","netloss 10 0.48425944104178337\n","accuracy:83.585%\n","log_loss 0.4998775623768462\n","********************\n","netloss 11 0.45345983134390994\n","accuracy:84.161%\n","log_loss 0.501279372424071\n","********************\n","netloss 12 0.4279398198588362\n","accuracy:84.377%\n","log_loss 0.4902063405798013\n","********************\n","netloss 13 0.4064479996503042\n","accuracy:84.737%\n","log_loss 0.4843718832034238\n","********************\n","netloss 14 0.39590551397112284\n","accuracy:85.781%\n","log_loss 0.4800911802366655\n","********************\n","netloss 15 0.3823443691816151\n","accuracy:86.105%\n","log_loss 0.464781304309134\n","********************\n","netloss 16 0.37098476862204327\n","accuracy:85.817%\n","log_loss 0.44742411794794207\n","********************\n","Counter 1 of 5\n","netloss 17 0.34569332394320224\n","accuracy:86.177%\n","log_loss 0.4555624966359944\n","********************\n","netloss 18 0.33765588109995553\n","accuracy:85.277%\n","log_loss 0.45852813839096607\n","********************\n","Counter 1 of 5\n","netloss 19 0.32273658982146547\n","accuracy:87.041%\n","log_loss 0.43856167259461953\n","********************\n","netloss 20 0.3124142379567431\n","accuracy:86.141%\n","log_loss 0.45420417554492665\n","********************\n","Counter 1 of 5\n","netloss 21 0.29675037354777806\n","accuracy:85.817%\n","log_loss 0.44721420077823976\n","********************\n","Counter 2 of 5\n","netloss 22 0.2900723657997098\n","accuracy:85.673%\n","log_loss 0.44618116692521254\n","********************\n","Counter 3 of 5\n","netloss 23 0.27442817844792117\n","accuracy:87.113%\n","log_loss 0.43605243717514325\n","********************\n","netloss 24 0.259116620594835\n","accuracy:87.005%\n","log_loss 0.435509784478227\n","********************\n","Counter 1 of 5\n","netloss 25 0.25631690875086627\n","accuracy:86.357%\n","log_loss 0.4578653090311642\n","********************\n","Counter 2 of 5\n","netloss 26 0.2520247978039272\n","accuracy:86.969%\n","log_loss 0.44504275225936557\n","********************\n","Counter 3 of 5\n","netloss 27 0.2422880901766624\n","accuracy:86.105%\n","log_loss 0.4685912330849222\n","********************\n","Counter 4 of 5\n","netloss 28 0.2407149311389694\n","accuracy:86.681%\n","log_loss 0.43317342621977156\n","********************\n","Counter 5 of 5\n","netloss 29 0.22889779070383107\n","accuracy:86.897%\n","log_loss 0.4465516764168173\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8711) and val_acc for this epoch:  tensor(0.8690) ...\n","****************************************\n","train_index [    0     2     4 ... 13884 13885 13886]\n","test_index [    1     3    10 ... 13880 13881 13883]\n","fold: 2\n","netloss 0 1.4629426052742494\n","accuracy:46.957%\n","log_loss 1.380443821880377\n","********************\n","netloss 1 1.2650105937813316\n","accuracy:56.032%\n","log_loss 1.218954663635252\n","********************\n","netloss 2 1.0598520007649213\n","accuracy:69.283%\n","log_loss 0.9569545294558112\n","********************\n","netloss 3 0.8632421253804249\n","accuracy:74.793%\n","log_loss 0.8034119567684521\n","********************\n","netloss 4 0.7357394940442686\n","accuracy:77.926%\n","log_loss 0.7055979355926374\n","********************\n","netloss 5 0.6526180386026795\n","accuracy:78.250%\n","log_loss 0.6806510496551065\n","********************\n","netloss 6 0.6102632143756096\n","accuracy:79.834%\n","log_loss 0.6588103165422446\n","********************\n","netloss 7 0.5793520078506715\n","accuracy:81.383%\n","log_loss 0.6145929689699617\n","********************\n","netloss 8 0.5298902493072367\n","accuracy:81.995%\n","log_loss 0.59176409202286\n","********************\n","netloss 9 0.491403795331506\n","accuracy:83.579%\n","log_loss 0.5274722596306963\n","********************\n","netloss 10 0.4652925550787925\n","accuracy:83.795%\n","log_loss 0.5201511390576843\n","********************\n","netloss 11 0.4308281609902146\n","accuracy:83.940%\n","log_loss 0.52518560344691\n","********************\n","netloss 12 0.4100937307504919\n","accuracy:85.308%\n","log_loss 0.499264707077608\n","********************\n","netloss 13 0.3907435722211281\n","accuracy:84.480%\n","log_loss 0.49572699754145766\n","********************\n","Counter 1 of 5\n","netloss 14 0.37345014192214554\n","accuracy:84.192%\n","log_loss 0.49279295010022633\n","********************\n","Counter 2 of 5\n","netloss 15 0.35250301962278213\n","accuracy:85.164%\n","log_loss 0.4849999001545864\n","********************\n","Counter 3 of 5\n","netloss 16 0.3350773767254889\n","accuracy:85.488%\n","log_loss 0.4888366581888328\n","********************\n","netloss 17 0.327950135995027\n","accuracy:85.632%\n","log_loss 0.4813708162403779\n","********************\n","netloss 18 0.31330840793259873\n","accuracy:85.416%\n","log_loss 0.4713552447323499\n","********************\n","Counter 1 of 5\n","netloss 19 0.3071493396965159\n","accuracy:85.128%\n","log_loss 0.4861584804153455\n","********************\n","Counter 2 of 5\n","netloss 20 0.29204161737429224\n","accuracy:86.424%\n","log_loss 0.46674348108397506\n","********************\n","netloss 21 0.2846647523369706\n","accuracy:86.748%\n","log_loss 0.44860207920748524\n","********************\n","netloss 22 0.26796666221173177\n","accuracy:86.604%\n","log_loss 0.4706611140170447\n","********************\n","Counter 1 of 5\n","netloss 23 0.26185903334664556\n","accuracy:85.776%\n","log_loss 0.46524696754935546\n","********************\n","Counter 2 of 5\n","netloss 24 0.24958022349965328\n","accuracy:85.128%\n","log_loss 0.49458350356254727\n","********************\n","Counter 3 of 5\n","netloss 25 0.2462278336888422\n","accuracy:86.640%\n","log_loss 0.4697404760604029\n","********************\n","Counter 4 of 5\n","netloss 26 0.23662131348810717\n","accuracy:86.496%\n","log_loss 0.4687313275366032\n","********************\n","Counter 5 of 5\n","netloss 27 0.22369857617127087\n","accuracy:87.432%\n","log_loss 0.4687515223837079\n","********************\n","netloss 28 0.2197684269970503\n","accuracy:85.164%\n","log_loss 0.49080080727834013\n","********************\n","Counter 1 of 5\n","netloss 29 0.2234160688724678\n","accuracy:86.568%\n","log_loss 0.4822626873137824\n","********************\n","Counter 2 of 5\n","netloss 30 0.21950005854359095\n","accuracy:86.064%\n","log_loss 0.48544399501995633\n","********************\n","Counter 3 of 5\n","netloss 31 0.204646418498656\n","accuracy:86.136%\n","log_loss 0.4932783401695052\n","********************\n","Counter 4 of 5\n","netloss 32 0.20390399081847815\n","accuracy:87.000%\n","log_loss 0.4690748372483205\n","********************\n","Counter 5 of 5\n","netloss 33 0.20116158688300748\n","accuracy:86.316%\n","log_loss 0.4852201788338497\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8743) and val_acc for this epoch:  tensor(0.8632) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13886]\n","test_index [    8     9    13 ... 13876 13882 13885]\n","fold: 3\n","netloss 0 1.4706634113791048\n","accuracy:49.838%\n","log_loss 1.375583536698036\n","********************\n","netloss 1 1.2253499149546363\n","accuracy:58.444%\n","log_loss 1.1505016743116596\n","********************\n","netloss 2 0.9831637438035842\n","accuracy:71.264%\n","log_loss 0.9386086282049173\n","********************\n","netloss 3 0.7957779106200682\n","accuracy:76.521%\n","log_loss 0.7926547332978175\n","********************\n","netloss 4 0.6898808853261791\n","accuracy:76.197%\n","log_loss 0.7449371490331302\n","********************\n","Counter 1 of 5\n","netloss 5 0.610683079880749\n","accuracy:79.402%\n","log_loss 0.6531502789542767\n","********************\n","netloss 6 0.5545223921907915\n","accuracy:79.726%\n","log_loss 0.6304457464534508\n","********************\n","netloss 7 0.5229964158646501\n","accuracy:81.959%\n","log_loss 0.5957329058743785\n","********************\n","netloss 8 0.48906817031405103\n","accuracy:82.427%\n","log_loss 0.5798375975423713\n","********************\n","netloss 9 0.45483326253983397\n","accuracy:82.499%\n","log_loss 0.5803663703669184\n","********************\n","netloss 10 0.425885252108479\n","accuracy:83.255%\n","log_loss 0.5653142402500231\n","********************\n","netloss 11 0.40871644663463896\n","accuracy:83.219%\n","log_loss 0.5438526222513638\n","********************\n","Counter 1 of 5\n","netloss 12 0.41604219691757044\n","accuracy:83.831%\n","log_loss 0.5507701957164112\n","********************\n","netloss 13 0.38544674889340663\n","accuracy:83.435%\n","log_loss 0.535861211063511\n","********************\n","Counter 1 of 5\n","netloss 14 0.3660205680617016\n","accuracy:84.804%\n","log_loss 0.534274784337805\n","********************\n","netloss 15 0.33530376550281765\n","accuracy:84.228%\n","log_loss 0.5289118185733714\n","********************\n","Counter 1 of 5\n","netloss 16 0.32239384426993367\n","accuracy:84.444%\n","log_loss 0.5067642854245795\n","********************\n","Counter 2 of 5\n","netloss 17 0.30061465207854\n","accuracy:84.372%\n","log_loss 0.5098733986250314\n","********************\n","Counter 3 of 5\n","netloss 18 0.2835604711632509\n","accuracy:84.264%\n","log_loss 0.5156209010721328\n","********************\n","Counter 4 of 5\n","netloss 19 0.27979664555283285\n","accuracy:84.984%\n","log_loss 0.49929123997280694\n","********************\n","netloss 20 0.26499950518925813\n","accuracy:85.704%\n","log_loss 0.5072464269268756\n","********************\n","netloss 21 0.25142265581549106\n","accuracy:84.912%\n","log_loss 0.516704655377903\n","********************\n","Counter 1 of 5\n","netloss 22 0.24638582317397167\n","accuracy:85.236%\n","log_loss 0.5239340252046351\n","********************\n","Counter 2 of 5\n","netloss 23 0.2348083042550387\n","accuracy:85.596%\n","log_loss 0.5067917525722203\n","********************\n","Counter 3 of 5\n","netloss 24 0.23085883448135686\n","accuracy:85.668%\n","log_loss 0.5066636071728465\n","********************\n","Counter 4 of 5\n","netloss 25 0.21993373180707138\n","accuracy:85.776%\n","log_loss 0.5021821445996065\n","********************\n","netloss 26 0.2114739449674631\n","accuracy:86.928%\n","log_loss 0.508503742027047\n","********************\n","netloss 27 0.20839926043211174\n","accuracy:85.668%\n","log_loss 0.5260871125369063\n","********************\n","Counter 1 of 5\n","netloss 28 0.2036081487223521\n","accuracy:86.352%\n","log_loss 0.5289253082383238\n","********************\n","Counter 2 of 5\n","netloss 29 0.19495744090036382\n","accuracy:86.604%\n","log_loss 0.5344341583650071\n","********************\n","Counter 3 of 5\n","netloss 30 0.18522279229073946\n","accuracy:86.460%\n","log_loss 0.5319848144138964\n","********************\n","Counter 4 of 5\n","netloss 31 0.18215834408364745\n","accuracy:86.100%\n","log_loss 0.530475366361916\n","********************\n","Counter 5 of 5\n","netloss 32 0.18381549315855408\n","accuracy:85.884%\n","log_loss 0.5368789389433681\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8693) and val_acc for this epoch:  tensor(0.8588) ...\n","****************************************\n","train_index [    1     3     4 ... 13883 13885 13886]\n","test_index [    0     2    15 ... 13868 13879 13884]\n","fold: 4\n","netloss 0 1.4763152638195756\n","accuracy:50.810%\n","log_loss 1.357872112941706\n","********************\n","netloss 1 1.2868326881410308\n","accuracy:58.516%\n","log_loss 1.1543625683916008\n","********************\n","netloss 2 1.0819137311678817\n","accuracy:66.727%\n","log_loss 0.9393402579272779\n","********************\n","netloss 3 0.8551344442081432\n","accuracy:74.757%\n","log_loss 0.7784874259447894\n","********************\n","netloss 4 0.7275622699660897\n","accuracy:78.178%\n","log_loss 0.6748631528347955\n","********************\n","netloss 5 0.6363627350783327\n","accuracy:80.086%\n","log_loss 0.6032060934942257\n","********************\n","netloss 6 0.576973746839942\n","accuracy:80.699%\n","log_loss 0.6059928954636711\n","********************\n","netloss 7 0.5383475147197033\n","accuracy:82.319%\n","log_loss 0.5531555914758642\n","********************\n","netloss 8 0.5013851699885068\n","accuracy:83.399%\n","log_loss 0.5363215495887343\n","********************\n","netloss 9 0.4579965989111393\n","accuracy:83.867%\n","log_loss 0.5034008517805915\n","********************\n","netloss 10 0.43536525981158214\n","accuracy:84.624%\n","log_loss 0.49619757939722103\n","********************\n","netloss 11 0.4041181039952332\n","accuracy:84.876%\n","log_loss 0.48847705687017123\n","********************\n","netloss 12 0.38102077392179545\n","accuracy:84.156%\n","log_loss 0.500394060863136\n","********************\n","Counter 1 of 5\n","netloss 13 0.35967534635254794\n","accuracy:85.020%\n","log_loss 0.4629251458374553\n","********************\n","netloss 14 0.3447870787296716\n","accuracy:84.984%\n","log_loss 0.47101905798977317\n","********************\n","Counter 1 of 5\n","netloss 15 0.3282485687574432\n","accuracy:84.876%\n","log_loss 0.4631783166322952\n","********************\n","Counter 2 of 5\n","netloss 16 0.3146365734724645\n","accuracy:84.552%\n","log_loss 0.46986548553724594\n","********************\n","Counter 3 of 5\n","netloss 17 0.30012215366042133\n","accuracy:86.100%\n","log_loss 0.4417603324836113\n","********************\n","netloss 18 0.28764315476940466\n","accuracy:86.748%\n","log_loss 0.4448037914911323\n","********************\n","netloss 19 0.2739729099195287\n","accuracy:86.388%\n","log_loss 0.45357994452923833\n","********************\n","Counter 1 of 5\n","netloss 20 0.2673049953769023\n","accuracy:86.712%\n","log_loss 0.4607219514309148\n","********************\n","Counter 2 of 5\n","netloss 21 0.25669554614144596\n","accuracy:86.100%\n","log_loss 0.4562285974406879\n","********************\n","Counter 3 of 5\n","netloss 22 0.24273860947438275\n","accuracy:86.604%\n","log_loss 0.4478113114387278\n","********************\n","Counter 4 of 5\n","netloss 23 0.23243858468109593\n","accuracy:85.884%\n","log_loss 0.46091014357647564\n","********************\n","Counter 5 of 5\n","netloss 24 0.2278822025934565\n","accuracy:86.892%\n","log_loss 0.43391010037199257\n","********************\n","netloss 25 0.21723966817756557\n","accuracy:85.056%\n","log_loss 0.47433805652688366\n","********************\n","Counter 1 of 5\n","netloss 26 0.21008183091317714\n","accuracy:86.604%\n","log_loss 0.4536496836008137\n","********************\n","Counter 2 of 5\n","netloss 27 0.20691333931136696\n","accuracy:86.352%\n","log_loss 0.4747571047341064\n","********************\n","Counter 3 of 5\n","netloss 28 0.19679653636977434\n","accuracy:86.064%\n","log_loss 0.47295204380087025\n","********************\n","Counter 4 of 5\n","netloss 29 0.1935373198175963\n","accuracy:86.892%\n","log_loss 0.46721122856679637\n","********************\n","Counter 5 of 5\n","netloss 30 0.1904424586518297\n","accuracy:87.108%\n","log_loss 0.46911238386153625\n","********************\n","netloss 31 0.1869358850738421\n","accuracy:86.640%\n","log_loss 0.4726320088254268\n","********************\n","Counter 1 of 5\n","netloss 32 0.17827429043735513\n","accuracy:86.748%\n","log_loss 0.46683009999013975\n","********************\n","Counter 2 of 5\n","netloss 33 0.1734250488358995\n","accuracy:86.316%\n","log_loss 0.477070292926211\n","********************\n","Counter 3 of 5\n","netloss 34 0.17114910718815773\n","accuracy:87.252%\n","log_loss 0.48608073201247026\n","********************\n","netloss 35 0.16153113324682283\n","accuracy:85.776%\n","log_loss 0.509100573150959\n","********************\n","Counter 1 of 5\n","netloss 36 0.14896700586961492\n","accuracy:86.604%\n","log_loss 0.4803575778556766\n","********************\n","Counter 2 of 5\n","netloss 37 0.14940192885399503\n","accuracy:86.316%\n","log_loss 0.5056331557672986\n","********************\n","Counter 3 of 5\n","netloss 38 0.14876467697340298\n","accuracy:86.172%\n","log_loss 0.5125353896660173\n","********************\n","Counter 4 of 5\n","netloss 39 0.14412131573576467\n","accuracy:86.784%\n","log_loss 0.5002976578081691\n","********************\n","Counter 5 of 5\n","netloss 40 0.1408934414334863\n","accuracy:86.604%\n","log_loss 0.5088566980595917\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8725) and val_acc for this epoch:  tensor(0.8660) ...\n","****************************************\n","0.8709586848464438\n"]}],"source":["labels=[0,1,2,3,4,5,6,7]\n","list_score=[]\n","for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","    print(\"train_index\",train_index)\n","    print(\"test_index\",test_index)\n","    ### Dividing data into folds\n","    x_train_fold = x_train[train_index]\n","    x_test_fold = x_train[test_index]\n","    y_train_fold = y_train[train_index]\n","    y_test_fold = y_train[test_index]\n","    train = MyDataset(x_train_fold, y_train_fold)\n","    test = MyDataset(x_test_fold, y_test_fold)\n","    train_loader = DataLoader(train, batch_size = 8, shuffle = True)\n","    test_loader = DataLoader(test, batch_size = 8, shuffle = False)\n","    print(\"fold:\",fold)\n","    max_score=[]\n","    # model = Net().to(device)\n","    best_acc=0\n","    model = MobileNet().to(device)\n","    loss_fn = nn.NLLLoss()\n","    optimizer = torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.5)\n","    for i in range(50):\n","      list1=[]\n","      for t, (data, target) in enumerate(train_loader):\n","        # print(\"t\",t)\n","        data,target = Variable(data.to(device)),Variable(target.to(device))\n","        # print(data.shape)\n","        pred = model(data.double().to(device))\n","        loss = loss_fn(pred,target)\n","        \n","        list1.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # print(\"loss\",loss.item())\n","      print(\"netloss\",i,np.mean(list1))\n","      with torch.no_grad():\n","        list_loss=[]\n","        correct = 0\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data.double().to(device))\n","            # get the index of the max log-probability\n","            pred = output.data.max(1, keepdim=True)[1]\n","            pred_loss=np.exp(output.data.cpu())\n","            logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","            list_loss.append(logsloss)\n","            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","        print('accuracy:{:.3f}%'.format(\n","            100. * correct / len(test_loader.dataset)))\n","        val_acc=correct / len(test_loader.dataset)\n","        print(\"log_loss\",sum(list_loss)/len(list_loss))\n","        print(\"*\"*20)\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            es = 0\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            if es > 5:\n","                print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","                break\n","    list_score.append(best_acc)\n","    print(\"*\"*40)\n","from numpy import mean\n","print(mean(list_score))\n"],"id":"Mxx3MA-eeOy-"},{"cell_type":"code","source":["print(mean(list_score))\n"],"metadata":{"id":"20cd75rdP6qS"},"id":"20cd75rdP6qS","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"MobileNet.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}