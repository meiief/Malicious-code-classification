{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bd0e5ef3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"],"id":"bd0e5ef3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22983,"status":"ok","timestamp":1658059017546,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"Ge3f2PhuyWRd","outputId":"e5a4c3f4-a42e-499f-b4d5-c9233061e76e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"Ge3f2PhuyWRd"},{"cell_type":"markdown","metadata":{"id":"SHuCCF5Bgorp"},"source":["# test"],"id":"SHuCCF5Bgorp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSTWoAm8fIat"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import torch.nn as nn\n","from torchvision import datasets,transforms"],"id":"hSTWoAm8fIat"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1658059020457,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"QVC3JbajfP1L","outputId":"f3f75011-cd68-4f2f-acc9-cabcd871386e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'NPY数据格式'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import numpy as np\n","import skimage\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","torch.manual_seed(1)  # reproducible\n","torch.set_default_tensor_type(torch.DoubleTensor)\n","from PIL import Image\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n","])\n","'''NPY数据格式'''\n","# class MyDataset(Dataset):\n","#     def __init__(self, data,label):\n","#         self.data = np.load(data) #加载npy数据\n","#         # self.data=self.data\n","#         self.label = np.load(label)\n","#         self.transforms = transform #转为tensor形式\n","#     def __getitem__(self, index):\n","#         hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","#         # print(hdct.shape)\n","#         # hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         # ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         # hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         # ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","#         hdct = hdct.astype(\"float\")\n","#         hdct= self.transforms(hdct)  #转为tensor形式\n","#         # ldct= self.transforms(ldct)  #转为tensor形式？??\n","#         return hdct, self.label[index] #返回数据还有标签\n","#     def __len__(self):\n","#         return self.data.shape[0] #返回数据的总个数\n"," \n","# def main():\n","#     dataset=MyDataset('train1.npy',\"label.npy\")\n","#     data= DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True)\n","# if __name__ == '__main__':\n","#     main()"],"id":"QVC3JbajfP1L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRkqYafGMgY_"},"outputs":[],"source":["\n","class MyDataset(Dataset):\n","    def __init__(self, data,label):\n","        self.data = data #加载npy数据\n","        self.label = label\n","        self.transforms = transform #转为tensor形式\n","    def __getitem__(self, index):\n","        hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","        hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","        hdct= self.transforms(hdct)  #转为tensor形式\n","#         ldct= self.transforms(ldct)  #转为tensor形式\n","        return hdct, self.label[index] #返回数据还有标签\n","    def __len__(self):\n","        return self.data.shape[0] #返回数据的总个数\n","\n"],"id":"FRkqYafGMgY_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XccgOoeHfQhK"},"outputs":[],"source":["# dataset=MyDataset('/content/drive/MyDrive/100/test3/x_train.npy',\"/content/drive/MyDrive/100/test3/y_train.npy\")\n","# dataset_test=MyDataset('/content/drive/MyDrive/100/test3/x_test.npy',\"/content/drive/MyDrive/100/test3/y_test.npy\")\n","# train_loader= DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n","# test_loader= DataLoader(dataset_test, batch_size=128, shuffle=False, pin_memory=True)"],"id":"XccgOoeHfQhK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"77FUNJqsgPFT"},"outputs":[],"source":["\n","__all__ = ['ResNet50', 'ResNet101','ResNet152']\n","\n","def Conv1(in_planes, places, stride=2):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels=in_planes,out_channels=places,kernel_size=7,stride=stride,padding=3, bias=False),\n","        nn.BatchNorm2d(places),\n","        nn.ReLU(inplace=True),\n","        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","    )\n","\n","class Bottleneck(nn.Module):\n","    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 4):\n","        super(Bottleneck,self).__init__()\n","        self.expansion = expansion\n","        self.downsampling = downsampling\n","\n","        self.bottleneck = nn.Sequential(\n","            nn.Conv2d(in_channels=in_places,out_channels=places,kernel_size=1,stride=1, bias=False),\n","            nn.BatchNorm2d(places),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(places),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=places, out_channels=places*self.expansion, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(places*self.expansion),\n","        )\n","\n","        if self.downsampling:\n","            self.downsample = nn.Sequential(\n","                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(places*self.expansion)\n","            )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.bottleneck(x)\n","\n","        if self.downsampling:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self,blocks, num_classes=8, expansion = 4):\n","        super(ResNet,self).__init__()\n","        self.expansion = expansion\n","\n","        self.conv1 = Conv1(in_planes = 3, places= 64)\n","\n","        self.layer1 = self.make_layer(in_places = 64, places= 64, block=blocks[0], stride=1)\n","        self.layer2 = self.make_layer(in_places = 256,places=128, block=blocks[1], stride=2)\n","        self.layer3 = self.make_layer(in_places=512,places=256, block=blocks[2], stride=2)\n","        self.layer4 = self.make_layer(in_places=1024,places=512, block=blocks[3], stride=2)\n","\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(8192,200)\n","        self.fc2 = nn.Linear(200,num_classes)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def make_layer(self, in_places, places, block, stride):\n","        layers = []\n","        layers.append(Bottleneck(in_places, places,stride, downsampling =True))\n","        for i in range(1, block):\n","            layers.append(Bottleneck(places*self.expansion, places))\n","\n","        return nn.Sequential(*layers)\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        x = self.fc2(x)\n","        \n","        return self.logsoftmax(x)\n","\n","def ResNet50():\n","    return ResNet([3, 4, 6, 3])\n","\n","def ResNet101():\n","    return ResNet([3, 4, 23, 3])\n","\n","def ResNet152():\n","    return ResNet([3, 8, 36, 3])"],"id":"77FUNJqsgPFT"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gamlC49rzhFD"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"id":"gamlC49rzhFD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658059020458,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"_9CyXHaV0BcU","outputId":"24fa2e1e-0e6a-4d8b-e673-527a239694ba"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["device"],"id":"_9CyXHaV0BcU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PJAzvpVgQ5L"},"outputs":[],"source":["model = ResNet50().to(device)"],"id":"3PJAzvpVgQ5L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKL2sWm3gTkc"},"outputs":[],"source":["loss_fn = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.008,momentum=0.5)"],"id":"rKL2sWm3gTkc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddSYnWMXL39j"},"outputs":[],"source":["from sklearn.metrics import log_loss\n","from sklearn.model_selection import KFold as kFold"],"id":"ddSYnWMXL39j"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7XpmGswIL48y"},"outputs":[],"source":["x_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/train_3channel.npy\")\n","y_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/label.npy\")"],"id":"7XpmGswIL48y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Xqth6cMOU4G"},"outputs":[],"source":["# da1=np.load('/content/drive/MyDrive/100/test3/x_test.npy')\n","x_train=x_train.reshape(13887,236,236,-1)"],"id":"9Xqth6cMOU4G"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658059074904,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"VB91F5wbOElq","outputId":"f0f9860f-9f76-4742-a9fd-87fb0ec22bbb"},"outputs":[{"data":{"text/plain":["(13887, 236, 236, 3)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"],"id":"VB91F5wbOElq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhQ3XPUrL6YV"},"outputs":[],"source":["kfold =kFold(n_splits=5,shuffle=True,random_state=1)"],"id":"DhQ3XPUrL6YV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjSk5oWyuWp9"},"outputs":[],"source":["import time"],"id":"wjSk5oWyuWp9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4EH6zEdMACZ","outputId":"9af632f2-3245-459e-b005-8c95a100aff9"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_index [    0     1     2 ... 13884 13885 13886]\n","test_index [    4     5     6 ... 13861 13872 13877]\n","fold: 0\n","netloss 0 1.4712663527459429\n","accuracy:50.972%\n","log_loss 1.4013622103169192\n","********************\n","netloss 1 1.0924889784705276\n","accuracy:65.587%\n","log_loss 1.074192525346613\n","********************\n","netloss 2 0.8794961562271655\n","accuracy:69.582%\n","log_loss 0.9445064034740145\n","********************\n","netloss 3 0.7700175565007278\n","accuracy:72.714%\n","log_loss 0.9106128648186768\n","********************\n","netloss 4 0.6968674937831847\n","accuracy:79.770%\n","log_loss 0.6403219766237334\n","********************\n","netloss 5 0.645062826362993\n","accuracy:80.994%\n","log_loss 0.6114341181035724\n","********************\n","netloss 6 0.6051424559116392\n","accuracy:78.330%\n","log_loss 0.6645491096155313\n","********************\n","Counter 1 of 5\n","netloss 7 0.5718186300762017\n","accuracy:83.405%\n","log_loss 0.5788679055667972\n","********************\n","netloss 8 0.5391746339577858\n","accuracy:83.189%\n","log_loss 0.5300530272363388\n","********************\n","Counter 1 of 5\n","netloss 9 0.5100492401709744\n","accuracy:83.765%\n","log_loss 0.5270234904552188\n","********************\n","netloss 10 0.4887626401622396\n","accuracy:83.981%\n","log_loss 0.5120724183157234\n","********************\n","netloss 11 0.4672571090683279\n","accuracy:82.217%\n","log_loss 0.5652818297823605\n","********************\n","Counter 1 of 5\n","netloss 12 0.44873994734779804\n","accuracy:85.133%\n","log_loss 0.5014820152858301\n","********************\n","netloss 13 0.4234710625426121\n","accuracy:85.349%\n","log_loss 0.4756276522652997\n","********************\n","netloss 14 0.4180023301479563\n","accuracy:84.413%\n","log_loss 0.496680401624853\n","********************\n","Counter 1 of 5\n","netloss 15 0.3966396898410978\n","accuracy:84.953%\n","log_loss 0.47816680407144496\n","********************\n","Counter 2 of 5\n","netloss 16 0.38263548078571497\n","accuracy:86.141%\n","log_loss 0.45091853968667617\n","********************\n","netloss 17 0.3752630934143422\n","accuracy:85.601%\n","log_loss 0.49528391131683236\n","********************\n","Counter 1 of 5\n","netloss 18 0.3559159350683263\n","accuracy:85.385%\n","log_loss 0.5212925381958505\n","********************\n","Counter 2 of 5\n","netloss 19 0.34755868467203793\n","accuracy:85.097%\n","log_loss 0.45690427677560963\n","********************\n","Counter 3 of 5\n","netloss 20 0.33658823422472123\n","accuracy:86.069%\n","log_loss 0.4912113572613667\n","********************\n","Counter 4 of 5\n","netloss 21 0.3270332019211033\n","accuracy:83.045%\n","log_loss 0.5460248927323573\n","********************\n","Counter 5 of 5\n","Early stopping with best_acc:  tensor(0.8614) and val_acc for this epoch:  tensor(0.8305) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13885]\n","test_index [   16    21    24 ... 13866 13867 13886]\n","fold: 1\n","netloss 0 1.45159889587021\n","accuracy:57.739%\n","log_loss 1.1979629359140231\n","********************\n","netloss 1 1.0581653583720902\n","accuracy:69.006%\n","log_loss 0.9055448866290273\n","********************\n","netloss 2 0.8619615898310773\n","accuracy:70.914%\n","log_loss 0.8849895197431682\n","********************\n","netloss 3 0.7578209523517838\n","accuracy:78.330%\n","log_loss 0.7211703195960304\n","********************\n","netloss 4 0.7024446914650971\n","accuracy:76.998%\n","log_loss 0.7561469642941943\n","********************\n","Counter 1 of 5\n","netloss 5 0.6512252389509027\n","accuracy:80.778%\n","log_loss 0.6230919347561484\n","********************\n","netloss 6 0.6087690022125871\n","accuracy:81.066%\n","log_loss 0.5796632430026524\n","********************\n","netloss 7 0.5780109919328176\n","accuracy:81.785%\n","log_loss 0.5977710246258074\n","********************\n","netloss 8 0.5459374411796986\n","accuracy:83.153%\n","log_loss 0.5512517391167894\n","********************\n","netloss 9 0.5222543576949555\n","accuracy:82.037%\n","log_loss 0.5576860548996782\n","********************\n","Counter 1 of 5\n","netloss 10 0.49496577150328097\n","accuracy:82.361%\n","log_loss 0.5432612826328932\n","********************\n","Counter 2 of 5\n","netloss 11 0.47685675123224297\n","accuracy:83.477%\n","log_loss 0.5219753034626563\n","********************\n","netloss 12 0.45688813968570235\n","accuracy:84.269%\n","log_loss 0.4996629005291133\n","********************\n","netloss 13 0.4347366822223365\n"]}],"source":["# labels=[0,1,2,3,4,5,6,7]\n","# list_score=[]\n","# for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","#     print(\"train_index\",train_index)\n","#     print(\"test_index\",test_index)\n","#     ### Dividing data into folds\n","#     x_train_fold = x_train[train_index]\n","#     x_test_fold = x_train[test_index]\n","#     y_train_fold = y_train[train_index]\n","#     y_test_fold = y_train[test_index]\n","#     train = MyDataset(x_train_fold, y_train_fold)\n","#     test = MyDataset(x_test_fold, y_test_fold)\n","#     train_loader = DataLoader(train, batch_size = 8, shuffle = True)\n","#     test_loader = DataLoader(test, batch_size = 8, shuffle = True)\n","#     print(\"fold:\",fold)\n","#     max_score=[]\n","#     # model = Net().to(device)\n","#     best_acc=0\n","#     model = ResNet50().to(device)\n","#     loss_fn = nn.NLLLoss()\n","#     optimizer = torch.optim.SGD(model.parameters(),lr=0.005,momentum=0.5)\n","#     for i in range(30):\n","#       list1=[]\n","#       for t, (data, target) in enumerate(train_loader):\n","#         # print(\"t\",t)\n","#         data,target = Variable(data.to(device)),Variable(target.to(device))\n","#         # print(data.shape)\n","#         pred = model(data.double().to(device))\n","#         loss = loss_fn(pred,target)\n","        \n","#         list1.append(loss.item())\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         optimizer.step()\n","#         # print(\"loss\",loss.item())\n","#       print(\"netloss\",i,np.mean(list1))\n","#       with torch.no_grad():\n","#         list_loss=[]\n","#         correct = 0\n","#         for data, target in test_loader:\n","#             data, target = data.to(device), target.to(device)\n","#             output = model(data.double().to(device))\n","#             # get the index of the max log-probability\n","#             pred = output.data.max(1, keepdim=True)[1]\n","#             pred_loss=np.exp(output.data.cpu())\n","#             logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","#             list_loss.append(logsloss)\n","#             correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","#         print('accuracy:{:.3f}%'.format(\n","#             100. * correct / len(test_loader.dataset)))\n","#         val_acc=correct / len(test_loader.dataset)\n","#         print(\"log_loss\",sum(list_loss)/len(list_loss))\n","#         print(\"*\"*20)\n","#         if val_acc > best_acc:\n","#             best_acc = val_acc\n","#             es = 0\n","#         else:\n","#             es += 1\n","#             print(\"Counter {} of 5\".format(es))\n","#             if es > 4:\n","#                 print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","#                 break\n","#     list_score.append(best_acc)\n","#     print(\"*\"*40)\n","#     del train,x_train_fold,train_loader,test_loader,test,y_test_fold,x_test_fold,y_train_fold\n","#     import gc\n","#     gc.collect()\n","#     time.sleep(20)\n","# from numpy import mean\n","# print(mean(list_score))\n"],"id":"o4EH6zEdMACZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKTcuoPiNrwP"},"outputs":[],"source":["mean(list_score)"],"id":"UKTcuoPiNrwP"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTLNWaz51rEl","outputId":"7ea56064-efff-4f25-eb35-2d6c09272e80"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_index [    0     1     2 ... 13883 13884 13885]\n","test_index [   16    21    24 ... 13866 13867 13886]\n","fold: 1\n","netloss 0 1.4784420477979607\n","accuracy:55.400%\n","log_loss 1.2171844087043378\n","********************\n","netloss 1 1.0848883827824456\n","accuracy:70.842%\n","log_loss 0.8524711350011506\n","********************\n","netloss 2 0.8772512802359188\n","accuracy:72.822%\n","log_loss 0.8526367537384774\n","********************\n","netloss 3 0.7842084842655183\n","accuracy:75.594%\n","log_loss 0.718781070371376\n","********************\n","netloss 4 0.7162441988572403\n","accuracy:77.394%\n","log_loss 0.667001896657387\n","********************\n","netloss 5 0.6552038287296282\n","accuracy:79.770%\n","log_loss 0.6517169193468064\n","********************\n","netloss 6 0.6143899162015036\n","accuracy:82.541%\n","log_loss 0.560457954582815\n","********************\n","netloss 7 0.5714481710327588\n","accuracy:80.922%\n","log_loss 0.5651968160807422\n","********************\n","Counter 1 of 5\n","netloss 8 0.551115827334188\n","accuracy:81.246%\n","log_loss 0.5484642527836391\n","********************\n","Counter 2 of 5\n","netloss 9 0.5214176243312612\n","accuracy:80.346%\n","log_loss 0.5841638276564314\n","********************\n","Counter 3 of 5\n","netloss 10 0.5028929545503966\n","accuracy:81.533%\n","log_loss 0.5960946097192916\n","********************\n","Counter 4 of 5\n","netloss 11 0.4746587234065817\n","accuracy:82.181%\n","log_loss 0.5276501228829595\n","********************\n","Counter 5 of 5\n","Early stopping with best_acc:  tensor(0.8254) and val_acc for this epoch:  tensor(0.8218) ...\n","****************************************\n","train_index [    0     2     4 ... 13884 13885 13886]\n","test_index [    1     3    10 ... 13880 13881 13883]\n","fold: 2\n","netloss 0 1.4676641824074903\n","accuracy:54.375%\n","log_loss 1.321142803628664\n","********************\n","netloss 1 1.0906770518988897\n","accuracy:68.275%\n","log_loss 0.9842068023953291\n","********************\n","netloss 2 0.8820144210239536\n","accuracy:73.713%\n","log_loss 0.8277946486485186\n","********************\n","netloss 3 0.7755715483905914\n","accuracy:76.665%\n","log_loss 0.747194973756005\n","********************\n","netloss 4 0.7000729551650083\n","accuracy:70.688%\n","log_loss 0.8637166080510877\n","********************\n","Counter 1 of 5\n","netloss 5 0.653526472899771\n","accuracy:77.386%\n","log_loss 0.6839704164719586\n","********************\n","netloss 6 0.6077171408403621\n","accuracy:81.851%\n","log_loss 0.5725981541383401\n","********************\n","netloss 7 0.5599578301180276\n","accuracy:80.771%\n","log_loss 0.6338853295120298\n","********************\n","Counter 1 of 5\n","netloss 8 0.5323242683987033\n","accuracy:82.931%\n","log_loss 0.5445194330713385\n","********************\n","netloss 9 0.5128509534186798\n","accuracy:81.743%\n","log_loss 0.5445054242726481\n","********************\n","Counter 1 of 5\n","netloss 10 0.48355301044578286\n","accuracy:81.023%\n","log_loss 0.5871568872975781\n","********************\n","Counter 2 of 5\n","netloss 11 0.4589419057132801\n","accuracy:83.615%\n","log_loss 0.5525374943863427\n","********************\n","netloss 12 0.44771498516815017\n","accuracy:84.336%\n","log_loss 0.5107761076826699\n","********************\n","netloss 13 0.42725893412438537\n","accuracy:81.743%\n","log_loss 0.5554464419168318\n","********************\n","Counter 1 of 5\n","netloss 14 0.40888675205265373\n","accuracy:84.012%\n","log_loss 0.5352481815100434\n","********************\n","Counter 2 of 5\n","netloss 15 0.38662489807028555\n","accuracy:83.903%\n","log_loss 0.5261667549757116\n","********************\n","Counter 3 of 5\n","netloss 16 0.38239844396900474\n","accuracy:86.100%\n","log_loss 0.4855937982799611\n","********************\n","netloss 17 0.36453150382728094\n","accuracy:83.039%\n","log_loss 0.5665160347616839\n","********************\n","Counter 1 of 5\n","netloss 18 0.3497538203826231\n","accuracy:85.452%\n","log_loss 0.5336633067617721\n","********************\n","Counter 2 of 5\n","netloss 19 0.34326530944959294\n","accuracy:85.848%\n","log_loss 0.48828040259317096\n","********************\n","Counter 3 of 5\n","netloss 20 0.3302085897121695\n","accuracy:87.180%\n","log_loss 0.44140931537583844\n","********************\n","netloss 21 0.3091751821897159\n","accuracy:86.172%\n","log_loss 0.5293774122975455\n","********************\n","Counter 1 of 5\n","netloss 22 0.3051473260192691\n","accuracy:83.183%\n","log_loss 0.5467830088480771\n","********************\n","Counter 2 of 5\n","netloss 23 0.30301437285113036\n","accuracy:86.820%\n","log_loss 0.4682247547575891\n","********************\n","Counter 3 of 5\n","netloss 24 0.2899862484691673\n","accuracy:86.244%\n","log_loss 0.5402181632183501\n","********************\n","Counter 4 of 5\n","netloss 25 0.28343490767631535\n","accuracy:85.524%\n","log_loss 0.5125130820158362\n","********************\n","Counter 5 of 5\n","Early stopping with best_acc:  tensor(0.8718) and val_acc for this epoch:  tensor(0.8552) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13886]\n","test_index [    8     9    13 ... 13876 13882 13885]\n","fold: 3\n"]}],"source":["# labels=[0,1,2,3,4,5,6,7]\n","# list_score=[]\n","# for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","#   if fold ==0:\n","#     pass\n","#   else:\n","#     print(\"train_index\",train_index)\n","#     print(\"test_index\",test_index)\n","#     ### Dividing data into folds\n","#     x_train_fold = x_train[train_index]\n","#     x_test_fold = x_train[test_index]\n","#     y_train_fold = y_train[train_index]\n","#     y_test_fold = y_train[test_index]\n","#     train = MyDataset(x_train_fold, y_train_fold)\n","#     test = MyDataset(x_test_fold, y_test_fold)\n","#     train_loader = DataLoader(train, batch_size = 8, shuffle = True)\n","#     test_loader = DataLoader(test, batch_size = 8, shuffle = True)\n","#     print(\"fold:\",fold)\n","#     max_score=[]\n","#     # model = Net().to(device)\n","#     best_acc=0\n","#     model = ResNet50().to(device)\n","#     loss_fn = nn.NLLLoss()\n","#     optimizer = torch.optim.SGD(model.parameters(),lr=0.005,momentum=0.5)\n","#     for i in range(30):\n","#       list1=[]\n","#       for t, (data, target) in enumerate(train_loader):\n","#         # print(\"t\",t)\n","#         data,target = Variable(data.to(device)),Variable(target.to(device))\n","#         # print(data.shape)\n","#         pred = model(data.double().to(device))\n","#         loss = loss_fn(pred,target)\n","        \n","#         list1.append(loss.item())\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         optimizer.step()\n","#         # print(\"loss\",loss.item())\n","#       print(\"netloss\",i,np.mean(list1))\n","#       with torch.no_grad():\n","#         list_loss=[]\n","#         correct = 0\n","#         for data, target in test_loader:\n","#             data, target = data.to(device), target.to(device)\n","#             output = model(data.double().to(device))\n","#             # get the index of the max log-probability\n","#             pred = output.data.max(1, keepdim=True)[1]\n","#             pred_loss=np.exp(output.data.cpu())\n","#             logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","#             list_loss.append(logsloss)\n","#             correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","#         print('accuracy:{:.3f}%'.format(\n","#             100. * correct / len(test_loader.dataset)))\n","#         val_acc=correct / len(test_loader.dataset)\n","#         print(\"log_loss\",sum(list_loss)/len(list_loss))\n","#         print(\"*\"*20)\n","#         if val_acc > best_acc:\n","#             best_acc = val_acc\n","#             es = 0\n","#         else:\n","#             es += 1\n","#             print(\"Counter {} of 5\".format(es))\n","#             if es > 4:\n","#                 print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","#                 break\n","#     list_score.append(best_acc)\n","#     print(\"*\"*40)\n","#     del train,x_train_fold,train_loader,test_loader,test,y_test_fold,x_test_fold,y_train_fold\n","#     import gc\n","#     gc.collect()\n","#     time.sleep(20)\n","# from numpy import mean\n","# print(mean(list_score))\n"],"id":"OTLNWaz51rEl"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2mKAdlQA05b","executionInfo":{"status":"ok","timestamp":1658112933321,"user_tz":-480,"elapsed":438847,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}},"outputId":"f8e779fd-e258-4350-b5c5-048aa8bc4d6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_index [    0     1     2 ... 13883 13884 13886]\n","test_index [    8     9    13 ... 13876 13882 13885]\n","fold: 3\n","netloss 0 1.4810784750848907\n","accuracy:54.519%\n","log_loss 1.3081312726140788\n","********************\n","netloss 1 1.128782950623477\n","accuracy:68.023%\n","log_loss 0.9337413279062241\n","********************\n","netloss 2 0.8921824476366864\n","accuracy:71.264%\n","log_loss 0.8953130885018485\n","********************\n","netloss 3 0.763650426631659\n","accuracy:76.125%\n","log_loss 0.7634081970117871\n","********************\n","netloss 4 0.6922205174861856\n","accuracy:78.322%\n","log_loss 0.72829968362921\n","********************\n","netloss 5 0.6340897150151344\n","accuracy:79.078%\n","log_loss 0.6679522739483912\n","********************\n","netloss 6 0.5946184273867529\n","accuracy:79.690%\n","log_loss 0.6153683009006228\n","********************\n","netloss 7 0.5533235156933477\n","accuracy:77.170%\n","log_loss 0.6893562519319217\n","********************\n","Counter 1 of 5\n","netloss 8 0.5203606670560383\n","accuracy:81.275%\n","log_loss 0.5947676213544063\n","********************\n","netloss 9 0.4964030743264672\n","accuracy:81.671%\n","log_loss 0.5554312597153306\n","********************\n","netloss 10 0.46854941852696874\n","accuracy:81.383%\n","log_loss 0.6114826727308392\n","********************\n","Counter 1 of 5\n","netloss 11 0.4622592463294708\n","accuracy:83.075%\n","log_loss 0.5669545128588892\n","********************\n","netloss 12 0.43967249259417696\n","accuracy:79.726%\n","log_loss 0.5926085311645801\n","********************\n","Counter 1 of 5\n","netloss 13 0.417938954644398\n","accuracy:83.039%\n","log_loss 0.5915845489453148\n","********************\n","Counter 2 of 5\n","netloss 14 0.400699416795818\n","accuracy:83.363%\n","log_loss 0.5321060854775885\n","********************\n","netloss 15 0.3784470721248482\n","accuracy:83.976%\n","log_loss 0.5334847270110356\n","********************\n","netloss 16 0.365613997244754\n","accuracy:84.948%\n","log_loss 0.5101296842850727\n","********************\n","netloss 17 0.35836327437755455\n","accuracy:85.056%\n","log_loss 0.5195032224436056\n","********************\n","netloss 18 0.3472974451964401\n","accuracy:83.615%\n","log_loss 0.5166890898830072\n","********************\n","Counter 1 of 5\n","netloss 19 0.33182484592796707\n","accuracy:83.940%\n","log_loss 0.5573789500195686\n","********************\n","Counter 2 of 5\n","netloss 20 0.31601609666274455\n","accuracy:84.264%\n","log_loss 0.5627685767051035\n","********************\n","Counter 3 of 5\n","netloss 21 0.31295232343884116\n","accuracy:85.668%\n","log_loss 0.5095794980343\n","********************\n","netloss 22 0.2976054395901231\n","accuracy:85.092%\n","log_loss 0.5270094779651014\n","********************\n","Counter 1 of 5\n","netloss 23 0.29142706839745186\n","accuracy:85.344%\n","log_loss 0.5165993561226968\n","********************\n","Counter 2 of 5\n","netloss 24 0.2809766779316752\n","accuracy:86.100%\n","log_loss 0.513349860251691\n","********************\n","netloss 25 0.2722300450235141\n","accuracy:84.984%\n","log_loss 0.5211459634424125\n","********************\n","Counter 1 of 5\n","netloss 26 0.2592721719861905\n","accuracy:85.236%\n","log_loss 0.5900148503062913\n","********************\n","Counter 2 of 5\n","netloss 27 0.2534002095738798\n","accuracy:85.344%\n","log_loss 0.5624402693973762\n","********************\n","Counter 3 of 5\n","netloss 28 0.25074177193493297\n","accuracy:84.012%\n","log_loss 0.6065033905781286\n","********************\n","Counter 4 of 5\n","netloss 29 0.23513713052228738\n","accuracy:84.804%\n","log_loss 0.5469822962210306\n","********************\n","Counter 5 of 5\n","Early stopping with best_acc:  tensor(0.8610) and val_acc for this epoch:  tensor(0.8480) ...\n","****************************************\n","train_index [    1     3     4 ... 13883 13885 13886]\n","test_index [    0     2    15 ... 13868 13879 13884]\n","fold: 4\n","netloss 0 1.4743515786461001\n","accuracy:43.716%\n","log_loss 1.3595488307360577\n","********************\n","netloss 1 1.099918866255575\n","accuracy:69.752%\n","log_loss 0.8976809946847928\n","********************\n","netloss 2 0.8838179926177702\n","accuracy:73.533%\n","log_loss 0.7934488012114185\n","********************\n","netloss 3 0.7487287400180903\n","accuracy:71.732%\n","log_loss 0.8812709433904733\n","********************\n","Counter 1 of 5\n","netloss 4 0.6881651844531531\n","accuracy:78.790%\n","log_loss 0.6864857312535547\n","********************\n","netloss 5 0.635947995365457\n","accuracy:80.699%\n","log_loss 0.6079779089455519\n","********************\n","netloss 6 0.5948746344654112\n","accuracy:80.951%\n","log_loss 0.6081257532698964\n","********************\n","netloss 7 0.5606100176628689\n","accuracy:81.131%\n","log_loss 0.5756218007098471\n","********************\n","netloss 8 0.5246979923253208\n","accuracy:82.931%\n","log_loss 0.52639293883204\n","********************\n","netloss 9 0.4955726718624457\n","accuracy:80.230%\n","log_loss 0.5940665505513496\n","********************\n","Counter 1 of 5\n","netloss 10 0.4767859068603368\n","accuracy:82.355%\n","log_loss 0.5268816485591777\n","********************\n","Counter 2 of 5\n","netloss 11 0.4582204686908501\n","accuracy:84.480%\n","log_loss 0.49405295645387265\n","********************\n","netloss 12 0.4412982221154979\n","accuracy:82.679%\n","log_loss 0.524554454858696\n","********************\n","Counter 1 of 5\n","netloss 13 0.4127800800649069\n","accuracy:82.463%\n","log_loss 0.545102121389337\n","********************\n","Counter 2 of 5\n","netloss 14 0.4123045560566175\n","accuracy:84.840%\n","log_loss 0.4900130315220561\n","********************\n","netloss 15 0.3982929579414602\n","accuracy:84.984%\n","log_loss 0.4845147529374098\n","********************\n","netloss 16 0.3832372298667286\n","accuracy:83.759%\n","log_loss 0.5257122411680684\n","********************\n","Counter 1 of 5\n","netloss 17 0.3677257018253782\n","accuracy:78.502%\n","log_loss 0.6331254420811809\n","********************\n","Counter 2 of 5\n","netloss 18 0.35347489954765493\n","accuracy:84.876%\n","log_loss 0.4769353119063585\n","********************\n","Counter 3 of 5\n","netloss 19 0.33428304968408257\n","accuracy:85.056%\n","log_loss 0.4775371488271472\n","********************\n","netloss 20 0.3342940703101676\n","accuracy:84.228%\n","log_loss 0.506495679758032\n","********************\n","Counter 1 of 5\n","netloss 21 0.3245506064829095\n","accuracy:85.416%\n","log_loss 0.4530712727476753\n","********************\n","netloss 22 0.299001228302298\n","accuracy:86.424%\n","log_loss 0.4449311561145167\n","********************\n","netloss 23 0.30127289942957985\n","accuracy:87.000%\n","log_loss 0.4423118914251387\n","********************\n","netloss 24 0.2858102950518227\n","accuracy:86.028%\n","log_loss 0.4722245195283255\n","********************\n","Counter 1 of 5\n","netloss 25 0.27490009207905053\n","accuracy:82.895%\n","log_loss 0.5709796039321591\n","********************\n","Counter 2 of 5\n","netloss 26 0.26738326459121414\n","accuracy:85.056%\n","log_loss 0.5082370336566356\n","********************\n","Counter 3 of 5\n","netloss 27 0.26082186304387145\n","accuracy:85.560%\n","log_loss 0.47677171437115345\n","********************\n","Counter 4 of 5\n","netloss 28 0.2501961112481804\n","accuracy:85.812%\n","log_loss 0.4649443297358471\n","********************\n","Counter 5 of 5\n","Early stopping with best_acc:  tensor(0.8700) and val_acc for this epoch:  tensor(0.8581) ...\n","****************************************\n","0.8655023406553835\n"]}],"source":["labels=[0,1,2,3,4,5,6,7]\n","list_score=[]\n","for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","  if fold in[0,1,2]:\n","    pass\n","  else:\n","    print(\"train_index\",train_index)\n","    print(\"test_index\",test_index)\n","    ### Dividing data into folds\n","    x_train_fold = x_train[train_index]\n","    x_test_fold = x_train[test_index]\n","    y_train_fold = y_train[train_index]\n","    y_test_fold = y_train[test_index]\n","    train = MyDataset(x_train_fold, y_train_fold)\n","    test = MyDataset(x_test_fold, y_test_fold)\n","    train_loader = DataLoader(train, batch_size = 8, shuffle = True)\n","    test_loader = DataLoader(test, batch_size = 8, shuffle = True)\n","    print(\"fold:\",fold)\n","    max_score=[]\n","    # model = Net().to(device)\n","    best_acc=0\n","    model = ResNet50().to(device)\n","    loss_fn = nn.NLLLoss()\n","    optimizer = torch.optim.SGD(model.parameters(),lr=0.005,momentum=0.5)\n","    for i in range(30):\n","      list1=[]\n","      for t, (data, target) in enumerate(train_loader):\n","        # print(\"t\",t)\n","        data,target = Variable(data.to(device)),Variable(target.to(device))\n","        # print(data.shape)\n","        pred = model(data.double().to(device))\n","        loss = loss_fn(pred,target)\n","        \n","        list1.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # print(\"loss\",loss.item())\n","      print(\"netloss\",i,np.mean(list1))\n","      with torch.no_grad():\n","        list_loss=[]\n","        correct = 0\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data.double().to(device))\n","            # get the index of the max log-probability\n","            pred = output.data.max(1, keepdim=True)[1]\n","            pred_loss=np.exp(output.data.cpu())\n","            logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","            list_loss.append(logsloss)\n","            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","        print('accuracy:{:.3f}%'.format(\n","            100. * correct / len(test_loader.dataset)))\n","        val_acc=correct / len(test_loader.dataset)\n","        print(\"log_loss\",sum(list_loss)/len(list_loss))\n","        print(\"*\"*20)\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            es = 0\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            if es > 4:\n","                print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","                break\n","    list_score.append(best_acc)\n","    print(\"*\"*40)\n","    del train,x_train_fold,train_loader,test_loader,test,y_test_fold,x_test_fold,y_train_fold\n","    import gc\n","    gc.collect()\n","    time.sleep(20)\n","from numpy import mean\n","print(mean(list_score))\n"],"id":"N2mKAdlQA05b"},{"cell_type":"code","source":["(0.8655023406553835*2+0.8718+0.8254+0.8614)/5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_NNZAab8Ejb","executionInfo":{"status":"ok","timestamp":1658158429574,"user_tz":-480,"elapsed":459,"user":{"displayName":"zhen fei","userId":"06736413076610031297"}},"outputId":"24c70f2e-6def-4134-9e36-106b6274dad6"},"id":"q_NNZAab8Ejb","execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8579209362621534"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[""],"metadata":{"id":"9oQUM1pN8a_K"},"id":"9oQUM1pN8a_K","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Copy of MobileNet.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}