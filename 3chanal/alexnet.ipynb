{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bd0e5ef3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4149,"status":"ok","timestamp":1657712603583,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"Ge3f2PhuyWRd","outputId":"92134bad-64bb-4957-a289-ef21808e823c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"SHuCCF5Bgorp"},"source":["# test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSTWoAm8fIat"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import torch.nn as nn\n","from torchvision import datasets,transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1657712606458,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"QVC3JbajfP1L","outputId":"d9f8d19f-edb2-408f-b929-5e2579ccf779"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'NPY数据格式'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import numpy as np\n","import skimage\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","torch.manual_seed(1)  # reproducible\n","torch.set_default_tensor_type(torch.DoubleTensor)\n","from PIL import Image\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n","])\n","'''NPY数据格式'''\n","# class MyDataset(Dataset):\n","#     def __init__(self, data,label):\n","#         self.data = np.load(data) #加载npy数据\n","#         # self.data=self.data\n","#         self.label = np.load(label)\n","#         self.transforms = transform #转为tensor形式\n","#     def __getitem__(self, index):\n","#         hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","#         # print(hdct.shape)\n","#         # hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         # ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         # hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         # ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","#         hdct = hdct.astype(\"float\")\n","#         hdct= self.transforms(hdct)  #转为tensor形式\n","#         # ldct= self.transforms(ldct)  #转为tensor形式？??\n","#         return hdct, self.label[index] #返回数据还有标签\n","#     def __len__(self):\n","#         return self.data.shape[0] #返回数据的总个数\n"," \n","# def main():\n","#     dataset=MyDataset('train1.npy',\"label.npy\")\n","#     data= DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True)\n","# if __name__ == '__main__':\n","#     main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRkqYafGMgY_"},"outputs":[],"source":["\n","class MyDataset(Dataset):\n","    def __init__(self, data,label):\n","        self.data = data #加载npy数据\n","        self.label = label\n","        self.transforms = transform #转为tensor形式\n","    def __getitem__(self, index):\n","        hdct= self.data[index, :, :, :]  # 读取每一个npy的数据\n","        hdct = np.squeeze(hdct)  # 删掉一维的数据，就是把通道数这个维度删除\n","#         ldct = 2.5 * skimage.util.random_noise(hdct * (0.4 / 255), mode='poisson', seed=None) * 255 #加poisson噪声\n","#         hdct=Image.fromarray(np.uint8(hdct)) #转成image的形式\n","#         ldct=Image.fromarray(np.uint8(ldct)) #转成image的形式\n","        hdct= self.transforms(hdct)  #转为tensor形式\n","#         ldct= self.transforms(ldct)  #转为tensor形式\n","        return hdct, self.label[index] #返回数据还有标签\n","    def __len__(self):\n","        return self.data.shape[0] #返回数据的总个数\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XccgOoeHfQhK"},"outputs":[],"source":["# dataset=MyDataset('/content/drive/MyDrive/100/test3/x_train.npy',\"/content/drive/MyDrive/100/test3/y_train.npy\")\n","# dataset_test=MyDataset('/content/drive/MyDrive/100/test3/x_test.npy',\"/content/drive/MyDrive/100/test3/y_test.npy\")\n","# train_loader= DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n","# test_loader= DataLoader(dataset_test, batch_size=128, shuffle=False, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77FUNJqsgPFT"},"outputs":[],"source":["\n","\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes=8, init_weights=False):   \n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(  #打包\n","            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n","            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n","            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n","            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(p=0.5),\n","            #全链接\n","            nn.Linear(128 * 6 * 6, 512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(512, 64),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(64, num_classes),\n","        )\n","        if init_weights:\n","            self._initialize_weights()\n","        self.bn = nn.BatchNorm2d(128)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.bn(x)\n","        x = torch.flatten(x, start_dim=1) #展平   或者view()\n","        x = self.classifier(x)\n","        return self.logsoftmax(x)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n","                nn.init.constant_(m.bias, 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gamlC49rzhFD"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1657712606459,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"_9CyXHaV0BcU","outputId":"c2486520-af0f-4e7d-d5ba-a97bce9e414d"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"elapsed":5,"status":"error","timestamp":1657723460833,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"PHbKU7CTA6_J"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"\u003cipython-input-22-b7253c647f73\u003e\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ！nvidia-smi\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"]}],"source":["from IPython.core.display import set_matplotlib_close\n","！nvidia-set_matplotlib_close"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PJAzvpVgQ5L"},"outputs":[],"source":["model = AlexNet().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKL2sWm3gTkc"},"outputs":[],"source":["loss_fn = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddSYnWMXL39j"},"outputs":[],"source":["from sklearn.metrics import log_loss\n","from sklearn.model_selection import KFold as kFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7XpmGswIL48y"},"outputs":[],"source":["x_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/train_3channel.npy\")\n","y_train=np.load(\"/content/drive/MyDrive/summer_start/data_generate/label.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Xqth6cMOU4G"},"outputs":[],"source":["# da1=np.load('/content/drive/MyDrive/100/test3/x_test.npy')\n","x_train=x_train.reshape(13887,236,236,-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1657712654192,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"VB91F5wbOElq","outputId":"ed2a23c0-a421-4291-e741-113c358c86cc"},"outputs":[{"data":{"text/plain":["(13887, 236, 236, 3)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhQ3XPUrL6YV"},"outputs":[],"source":["kfold =kFold(n_splits=5,shuffle=True,random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLcfvP6tgU8i"},"outputs":[],"source":["# for epoch in range(40):\n","\n","#   list1=[]\n","#   for t, (data, target) in enumerate(train_loader):\n","#     data,target = Variable(data.to(device)),Variable(target.to(device))\n","#     pred = model(data).to(device)\n","#     loss = loss_fn(pred,target)\n","#     list1.append(loss.item())\n","    \n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     # print(t,loss.item())\n","#   print(epoch,np.mean(list1))\n","#   if epoch%2==0:\n","#     correct = 0\n","#     for data, target in test_loader:\n","#         data, target = Variable(data.to(device), volatile=True), Variable(target.to(device))\n","#         output = model(data.to(device))\n","#         # get the index of the max log-probability\n","#         pred = output.data.max(1, keepdim=True)[1]\n","#         correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","#     print('{:.3f}%\\n'.format(\n","#         100. * correct / len(test_loader.dataset)))\n","#     correct=correct / len(test_loader.dataset)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjSk5oWyuWp9"},"outputs":[],"source":["import time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10493763,"status":"ok","timestamp":1657723147952,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"o4EH6zEdMACZ","outputId":"dda8daff-2a50-45ad-b90b-a47a93c9c9e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_index [    0     1     2 ... 13884 13885 13886]\n","test_index [    4     5     6 ... 13861 13872 13877]\n","fold: 0\n","netloss 0 1.6344146821569463\n","accuracy:52.376%\n","log_loss 1.4197901080020452\n","********************\n","netloss 1 1.3801070112693978\n","accuracy:55.436%\n","log_loss 1.3006827661554996\n","********************\n","netloss 2 1.2870977576014064\n","accuracy:57.235%\n","log_loss 1.2210546127983677\n","********************\n","netloss 3 1.2088667228786507\n","accuracy:59.611%\n","log_loss 1.1293194200853736\n","********************\n","netloss 4 1.1145148348514535\n","accuracy:65.191%\n","log_loss 1.023228763638207\n","********************\n","netloss 5 1.0225524102054904\n","accuracy:67.819%\n","log_loss 0.9685708006165847\n","********************\n","netloss 6 0.9687946763556031\n","accuracy:72.318%\n","log_loss 0.8795284287644037\n","********************\n","netloss 7 0.8617151540311623\n","accuracy:71.742%\n","log_loss 0.8543255240495083\n","********************\n","Counter 1 of 5\n","netloss 8 0.7960250596442853\n","accuracy:75.666%\n","log_loss 0.769121445131312\n","********************\n","netloss 9 0.7493531793937274\n","accuracy:76.782%\n","log_loss 0.7271808259574076\n","********************\n","netloss 10 0.6958160239371955\n","accuracy:77.790%\n","log_loss 0.7111703539355483\n","********************\n","netloss 11 0.6701176284156057\n","accuracy:77.934%\n","log_loss 0.682152513811186\n","********************\n","netloss 12 0.635682408493892\n","accuracy:79.806%\n","log_loss 0.6250568006875349\n","********************\n","netloss 13 0.6114770661490833\n","accuracy:79.302%\n","log_loss 0.6319433060479602\n","********************\n","Counter 1 of 5\n","netloss 14 0.5845294595120416\n","accuracy:80.886%\n","log_loss 0.6090882830999487\n","********************\n","netloss 15 0.5607050582618898\n","accuracy:82.001%\n","log_loss 0.5830490357321879\n","********************\n","netloss 16 0.5406324578811368\n","accuracy:82.433%\n","log_loss 0.5766705250372163\n","********************\n","netloss 17 0.5532411947284521\n","accuracy:82.577%\n","log_loss 0.5604409589504519\n","********************\n","netloss 18 0.5222606922761726\n","accuracy:81.677%\n","log_loss 0.5688770533730423\n","********************\n","Counter 1 of 5\n","netloss 19 0.49582759556502415\n","accuracy:82.685%\n","log_loss 0.5524211948403401\n","********************\n","netloss 20 0.4901462442167615\n","accuracy:82.721%\n","log_loss 0.545901986276501\n","********************\n","netloss 21 0.46973192711057676\n","accuracy:82.577%\n","log_loss 0.5578364366277314\n","********************\n","Counter 1 of 5\n","netloss 22 0.44909030159869184\n","accuracy:82.757%\n","log_loss 0.5389210731634972\n","********************\n","netloss 23 0.45580707990929403\n","accuracy:84.161%\n","log_loss 0.5219383768157909\n","********************\n","netloss 24 0.44193779353152646\n","accuracy:84.809%\n","log_loss 0.5084792295344572\n","********************\n","netloss 25 0.4223278895405214\n","accuracy:83.981%\n","log_loss 0.5110734700484633\n","********************\n","Counter 1 of 5\n","netloss 26 0.41618908729422405\n","accuracy:83.585%\n","log_loss 0.5369714844328878\n","********************\n","Counter 2 of 5\n","netloss 27 0.41214548353102876\n","accuracy:84.557%\n","log_loss 0.5287973479320569\n","********************\n","Counter 3 of 5\n","netloss 28 0.3930092722780952\n","accuracy:83.945%\n","log_loss 0.5159408898636322\n","********************\n","Counter 4 of 5\n","netloss 29 0.4176139278432194\n","accuracy:84.125%\n","log_loss 0.5064847289718478\n","********************\n","Counter 5 of 5\n","netloss 30 0.42039445781162105\n","accuracy:84.269%\n","log_loss 0.5364006554963917\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8481) and val_acc for this epoch:  tensor(0.8427) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13885]\n","test_index [   16    21    24 ... 13866 13867 13886]\n","fold: 1\n","netloss 0 1.5821957392997745\n","accuracy:49.316%\n","log_loss 1.4627167154630902\n","********************\n","netloss 1 1.3808962366658954\n","accuracy:52.808%\n","log_loss 1.3530465525956132\n","********************\n","netloss 2 1.2815236873192606\n","accuracy:54.320%\n","log_loss 1.2623138425756466\n","********************\n","netloss 3 1.188004170112805\n","accuracy:59.071%\n","log_loss 1.1276096823152124\n","********************\n","netloss 4 1.0906706749269102\n","accuracy:63.283%\n","log_loss 1.071007772500854\n","********************\n","netloss 5 0.9837927507294999\n","accuracy:63.679%\n","log_loss 1.0300090796103405\n","********************\n","netloss 6 0.8826488326184558\n","accuracy:70.410%\n","log_loss 0.9066661955896631\n","********************\n","netloss 7 0.8265628323806867\n","accuracy:75.306%\n","log_loss 0.7569893590137162\n","********************\n","netloss 8 0.7646703374297169\n","accuracy:75.126%\n","log_loss 0.7477528924132862\n","********************\n","Counter 1 of 5\n","netloss 9 0.7118040919316238\n","accuracy:77.358%\n","log_loss 0.6845081144227823\n","********************\n","accuracy:78.546%\n","log_loss 0.6449786219048024\n","********************\n","netloss 11 0.6499528913761257\n","accuracy:79.014%\n","log_loss 0.6603006352771562\n","********************\n","netloss 12 0.6276505830923228\n","accuracy:79.842%\n","log_loss 0.6046561563388473\n","********************\n","netloss 13 0.6061460474351859\n","accuracy:80.778%\n","log_loss 0.6078773072408458\n","********************\n","netloss 14 0.5736315206535861\n","accuracy:81.174%\n","log_loss 0.5857984040200106\n","********************\n","netloss 15 0.5733235925659564\n","accuracy:82.289%\n","log_loss 0.5610090455562841\n","********************\n","netloss 16 0.5457044328078042\n","accuracy:81.605%\n","log_loss 0.5601312615374043\n","********************\n","Counter 1 of 5\n","netloss 17 0.5202173680757988\n","accuracy:82.217%\n","log_loss 0.5518111943088851\n","********************\n","Counter 2 of 5\n","netloss 18 0.5017335490336603\n","accuracy:82.613%\n","log_loss 0.5345971932121685\n","********************\n","netloss 19 0.4883133404114029\n","accuracy:83.225%\n","log_loss 0.5353915954656647\n","********************\n","netloss 20 0.4752948664834197\n","accuracy:83.153%\n","log_loss 0.5128947387784012\n","********************\n","Counter 1 of 5\n","netloss 21 0.4651564181648075\n","accuracy:83.045%\n","log_loss 0.5266820201522983\n","********************\n","Counter 2 of 5\n","netloss 22 0.45139066395913385\n","accuracy:82.541%\n","log_loss 0.5231872273736108\n","********************\n","Counter 3 of 5\n","netloss 23 0.44729023331045015\n","accuracy:83.657%\n","log_loss 0.5248181497316681\n","********************\n","netloss 24 0.44462663441776273\n","accuracy:83.873%\n","log_loss 0.49614511371229925\n","********************\n","netloss 25 0.4228406171135274\n","accuracy:83.045%\n","log_loss 0.5180752405633183\n","********************\n","Counter 1 of 5\n","netloss 26 0.4088848271348304\n","accuracy:84.449%\n","log_loss 0.49386200941452646\n","********************\n","netloss 27 0.40326782528458127\n","accuracy:84.413%\n","log_loss 0.49808282964072825\n","********************\n","Counter 1 of 5\n","netloss 28 0.3916522403237551\n","accuracy:84.737%\n","log_loss 0.48148413096858766\n","********************\n","netloss 29 0.38970917872271005\n","accuracy:85.313%\n","log_loss 0.4867025247066099\n","********************\n","netloss 30 0.3740185326004406\n","accuracy:84.845%\n","log_loss 0.4819655838038886\n","********************\n","Counter 1 of 5\n","netloss 31 0.3622353125150894\n","accuracy:85.745%\n","log_loss 0.4577146204328685\n","********************\n","netloss 32 0.4143497492086556\n","accuracy:81.533%\n","log_loss 0.5758197630318149\n","********************\n","Counter 1 of 5\n","netloss 33 0.4348900201312287\n","accuracy:84.413%\n","log_loss 0.4959300455210782\n","********************\n","Counter 2 of 5\n","netloss 34 0.38428242896482323\n","accuracy:85.457%\n","log_loss 0.46161547953539084\n","********************\n","Counter 3 of 5\n","netloss 35 0.36516518516634144\n","accuracy:85.601%\n","log_loss 0.4673867621906277\n","********************\n","Counter 4 of 5\n","netloss 36 0.3557324548541595\n","accuracy:85.673%\n","log_loss 0.47643478219424734\n","********************\n","Counter 5 of 5\n","netloss 37 0.3409290003003408\n","accuracy:85.457%\n","log_loss 0.46726201649685606\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8575) and val_acc for this epoch:  tensor(0.8546) ...\n","****************************************\n","train_index [    0     2     4 ... 13884 13885 13886]\n","test_index [    1     3    10 ... 13880 13881 13883]\n","fold: 2\n","netloss 0 1.5825148804986895\n","accuracy:51.026%\n","log_loss 1.4500091146480094\n","********************\n","netloss 1 1.3742502159970569\n","accuracy:54.087%\n","log_loss 1.3297778900245991\n","********************\n","netloss 2 1.270286587595205\n","accuracy:57.328%\n","log_loss 1.1861492715365114\n","********************\n","netloss 3 1.1406991550822354\n","accuracy:64.026%\n","log_loss 1.0779241480539927\n","********************\n","netloss 4 1.0076296712980413\n","accuracy:69.716%\n","log_loss 0.9345732863876526\n","********************\n","netloss 5 0.9189694716692972\n","accuracy:71.012%\n","log_loss 0.9119775987108854\n","********************\n","netloss 6 0.8715024364893491\n","accuracy:74.901%\n","log_loss 0.821845579120455\n","********************\n","netloss 7 0.7803076300573918\n","accuracy:76.053%\n","log_loss 0.758880343732721\n","********************\n","netloss 8 0.7287666012523776\n","accuracy:77.350%\n","log_loss 0.7241610879301785\n","********************\n","netloss 9 0.6849602138013179\n","accuracy:77.926%\n","log_loss 0.6744864550126366\n","********************\n","netloss 10 0.6578207456508304\n","accuracy:78.646%\n","log_loss 0.6735490561004107\n","********************\n","netloss 11 0.6337676693840086\n","accuracy:80.411%\n","log_loss 0.6489980191221126\n","********************\n","netloss 12 0.5964627292685232\n","accuracy:80.411%\n","log_loss 0.6412766958995836\n","********************\n","Counter 1 of 5\n","netloss 13 0.5676375935928963\n","accuracy:81.815%\n","log_loss 0.6165482794440512\n","********************\n","netloss 14 0.5582397033287497\n","accuracy:81.491%\n","log_loss 0.6002751861010757\n","********************\n","Counter 1 of 5\n","netloss 15 0.5501265175436247\n","accuracy:81.455%\n","log_loss 0.5909377496156111\n","********************\n","Counter 2 of 5\n","netloss 16 0.5368796581913651\n","accuracy:81.491%\n","log_loss 0.5905618668958238\n","********************\n","Counter 3 of 5\n","netloss 17 0.5039973769741366\n","accuracy:82.463%\n","log_loss 0.5772254843347612\n","********************\n","netloss 18 0.5048706912142784\n","accuracy:82.679%\n","log_loss 0.5570627908038528\n","********************\n","netloss 19 0.49264970582477485\n","accuracy:82.715%\n","log_loss 0.5359522551146856\n","********************\n","netloss 20 0.46668464490077444\n","accuracy:83.399%\n","log_loss 0.5315655684640663\n","********************\n","netloss 21 0.45766968097656535\n","accuracy:83.183%\n","log_loss 0.5403741751161731\n","********************\n","Counter 1 of 5\n","netloss 22 0.44204439052381556\n","accuracy:83.831%\n","log_loss 0.5192323469412651\n","********************\n","netloss 23 0.4338523002647513\n","accuracy:83.147%\n","log_loss 0.5280041361809689\n","********************\n","Counter 1 of 5\n","netloss 24 0.42632632182564845\n","accuracy:84.408%\n","log_loss 0.5295872099059342\n","********************\n","netloss 25 0.4172844605137953\n","accuracy:84.840%\n","log_loss 0.4941031013150578\n","********************\n","netloss 26 0.41001043907090706\n","accuracy:84.804%\n","log_loss 0.5108053752744386\n","********************\n","Counter 1 of 5\n","netloss 27 0.40329180260349246\n","accuracy:82.391%\n","log_loss 0.5636779406471673\n","********************\n","Counter 2 of 5\n","netloss 28 0.39655543377855945\n","accuracy:84.408%\n","log_loss 0.5310856642741161\n","********************\n","Counter 3 of 5\n","netloss 29 0.38805136122986705\n","accuracy:84.156%\n","log_loss 0.511810958801189\n","********************\n","Counter 4 of 5\n","netloss 30 0.3804910607182568\n","accuracy:84.768%\n","log_loss 0.5113558820782372\n","********************\n","Counter 5 of 5\n","netloss 31 0.3606187406433313\n","accuracy:84.660%\n","log_loss 0.522736717256185\n","********************\n","Counter 6 of 5\n","Early stopping with best_acc:  tensor(0.8484) and val_acc for this epoch:  tensor(0.8466) ...\n","****************************************\n","train_index [    0     1     2 ... 13883 13884 13886]\n","test_index [    8     9    13 ... 13876 13882 13885]\n","fold: 3\n","netloss 0 1.6052612616019954\n","accuracy:50.198%\n","log_loss 1.4548798504986784\n","********************\n","netloss 1 1.3814106540826492\n","accuracy:54.015%\n","log_loss 1.363853859128265\n","********************\n","netloss 2 1.2627590627080012\n","accuracy:55.600%\n","log_loss 1.2961895094169182\n","********************\n","netloss 3 1.1472423866021662\n","accuracy:61.973%\n","log_loss 1.1058671110018414\n","********************\n","netloss 4 1.0114033898579087\n","accuracy:65.322%\n","log_loss 1.0258092476329355\n","********************\n","netloss 5 0.9310432674422675\n","accuracy:69.175%\n","log_loss 0.957159106043077\n","********************\n","netloss 6 0.8366453283613464\n","accuracy:72.452%\n","log_loss 0.8547533990913827\n","********************\n","netloss 7 0.7885320434021541\n","accuracy:72.740%\n","log_loss 0.8533887089838053\n","********************\n","netloss 8 0.7219725360807528\n","accuracy:73.749%\n","log_loss 0.7987012954457173\n","********************\n","netloss 9 0.6764096787802173\n","accuracy:75.981%\n","log_loss 0.7417626315586747\n","********************\n","netloss 10 0.6408722682890923\n","accuracy:77.422%\n","log_loss 0.7090674416213029\n","********************\n","netloss 11 0.6115723568735857\n","accuracy:77.746%\n","log_loss 0.7051073993857179\n","********************\n","netloss 12 0.5924459550031607\n","accuracy:78.574%\n","log_loss 0.6967137920516598\n","********************\n","netloss 13 0.573505441510975\n","accuracy:78.646%\n","log_loss 0.6724785906991674\n","********************\n","netloss 14 0.548966569796751\n","accuracy:80.375%\n","log_loss 0.6235338616010035\n","********************\n","netloss 15 0.5224413367818324\n","accuracy:79.258%\n","log_loss 0.6289208061430812\n","********************\n","Counter 1 of 5\n","netloss 16 0.5048329126374203\n","accuracy:78.106%\n","log_loss 0.6693921023516517\n","********************\n","Counter 2 of 5\n","netloss 17 0.48166913489485474\n","accuracy:81.131%\n","log_loss 0.5926925908289065\n","********************\n","netloss 18 0.4783474195747324\n","accuracy:80.086%\n","log_loss 0.6184858434392726\n","********************\n","Counter 1 of 5\n","netloss 19 0.4712830652887165\n","accuracy:81.203%\n","log_loss 0.5784090838894164\n","********************\n","netloss 20 0.4495068364884155\n","accuracy:82.427%\n","log_loss 0.5582136580875618\n","********************\n","netloss 21 0.44236909525904244\n","accuracy:82.679%\n","log_loss 0.5631857703915762\n","********************\n","netloss 22 0.43874820774767354\n","accuracy:80.771%\n","log_loss 0.6066677123323313\n","********************\n","Counter 1 of 5\n","netloss 23 0.4309648467679309\n","accuracy:83.255%\n","log_loss 0.5341559438546378\n","********************\n","netloss 24 0.41263816914843127\n","accuracy:82.571%\n","log_loss 0.5667192287281453\n","********************\n","Counter 1 of 5\n","netloss 25 0.40090267082925113\n","accuracy:81.563%\n","log_loss 0.5550220825391828\n","********************\n","Counter 2 of 5\n","netloss 26 0.3922737381613705\n","accuracy:82.139%\n","log_loss 0.5666964045658832\n","********************\n","Counter 3 of 5\n","netloss 27 0.3826103713318904\n","accuracy:83.219%\n","log_loss 0.5202763193262838\n","********************\n","Counter 4 of 5\n","netloss 28 0.378378078917743\n","accuracy:82.643%\n","log_loss 0.5722957724441409\n","********************\n","Counter 5 of 5\n","netloss 29 0.37895095324800554\n","accuracy:83.543%\n","log_loss 0.5224531979727969\n","********************\n","netloss 30 0.3627487771887896\n","accuracy:83.399%\n","log_loss 0.5403848763583239\n","********************\n","Counter 1 of 5\n","netloss 31 0.36033793997629543\n","accuracy:83.399%\n","log_loss 0.5360649410087946\n","********************\n","Counter 2 of 5\n","netloss 32 0.351625538973806\n","accuracy:84.120%\n","log_loss 0.5265857844454157\n","********************\n","netloss 33 0.33648177761402304\n","accuracy:84.228%\n","log_loss 0.5044853552295594\n","********************\n","netloss 34 0.35435689144065025\n","accuracy:83.543%\n","log_loss 0.5241251363186323\n","********************\n","Counter 1 of 5\n","netloss 35 0.3390307317470885\n","accuracy:83.507%\n","log_loss 0.5363481758253684\n","********************\n","Counter 2 of 5\n","netloss 36 0.3249103011809318\n","accuracy:82.391%\n","log_loss 0.6007011841245932\n","********************\n","Counter 3 of 5\n","netloss 37 0.327268234151325\n","accuracy:84.408%\n","log_loss 0.5021483804768455\n","********************\n","netloss 38 0.31861519832744506\n","accuracy:83.435%\n","log_loss 0.5463307191874103\n","********************\n","Counter 1 of 5\n","netloss 39 0.3268330296967593\n","accuracy:83.435%\n","log_loss 0.5325223678075651\n","********************\n","Counter 2 of 5\n","netloss 40 0.30986395567249797\n","accuracy:84.516%\n","log_loss 0.5217794638464144\n","********************\n","netloss 41 0.30907689033641983\n","accuracy:84.228%\n","log_loss 0.5372812585053571\n","********************\n","Counter 1 of 5\n","netloss 42 0.3125344543169526\n","accuracy:84.768%\n","log_loss 0.5110112235031815\n","********************\n","netloss 43 0.30184384247163787\n","accuracy:84.768%\n","log_loss 0.5172457118947504\n","********************\n","Counter 1 of 5\n","netloss 44 0.2884570231622769\n","accuracy:83.831%\n","log_loss 0.5332282870187903\n","********************\n","Counter 2 of 5\n","netloss 45 0.28782993266199747\n","accuracy:84.804%\n","log_loss 0.5170718276275974\n","********************\n","netloss 46 0.2882623013253464\n","accuracy:84.660%\n","log_loss 0.5322795528447642\n","********************\n","Counter 1 of 5\n","netloss 47 0.2823435314712821\n","accuracy:84.948%\n","log_loss 0.5179166211335565\n","********************\n","netloss 48 0.2760361798183115\n","accuracy:85.380%\n","log_loss 0.5067620471745912\n","********************\n","netloss 49 0.28230851165039117\n","accuracy:83.867%\n","log_loss 0.5481544603605304\n","********************\n","Counter 1 of 5\n","****************************************\n","train_index [    1     3     4 ... 13883 13885 13886]\n","test_index [    0     2    15 ... 13868 13879 13884]\n","fold: 4\n","netloss 0 1.5763534154858148\n","accuracy:50.342%\n","log_loss 1.4469564931732959\n","********************\n","netloss 1 1.378632907760114\n","accuracy:54.627%\n","log_loss 1.2952506297695878\n","********************\n","netloss 2 1.2636240557141363\n","accuracy:58.480%\n","log_loss 1.1938585537433541\n","********************\n","netloss 3 1.1708958607082594\n","accuracy:57.580%\n","log_loss 1.1909227762188792\n","********************\n","Counter 1 of 5\n","netloss 4 1.0976767534285699\n","accuracy:65.574%\n","log_loss 1.0459762894456166\n","********************\n","netloss 5 0.9800519586039709\n","accuracy:70.760%\n","log_loss 0.8977753305436551\n","********************\n","netloss 6 0.8723510627710079\n","accuracy:72.668%\n","log_loss 0.830260208601498\n","********************\n","netloss 7 0.8168181104055028\n","accuracy:74.649%\n","log_loss 0.8003355456225013\n","********************\n","netloss 8 0.7498799626615921\n","accuracy:74.901%\n","log_loss 0.7611579781743923\n","********************\n","netloss 9 0.7618040440057466\n","accuracy:66.295%\n","log_loss 0.9896401021244307\n","********************\n","Counter 1 of 5\n","netloss 10 0.6995509736719323\n","accuracy:78.610%\n","log_loss 0.6815261924094774\n","********************\n","netloss 11 0.653015025579632\n","accuracy:79.798%\n","log_loss 0.6385400161924223\n","********************\n","netloss 12 0.6202130701148953\n","accuracy:80.158%\n","log_loss 0.6349441306707991\n","********************\n","netloss 13 0.5890837730900883\n","accuracy:78.106%\n","log_loss 0.654181408352534\n","********************\n","Counter 1 of 5\n","netloss 14 0.5769844879198345\n","accuracy:81.311%\n","log_loss 0.580624172570436\n","********************\n","netloss 15 0.548759370939399\n","accuracy:80.375%\n","log_loss 0.5915029780243986\n","********************\n","Counter 1 of 5\n","netloss 16 0.5350982482091217\n","accuracy:81.923%\n","log_loss 0.5710864595617563\n","********************\n","netloss 17 0.5187446588474539\n","accuracy:81.527%\n","log_loss 0.5580659617421955\n","********************\n","Counter 1 of 5\n","netloss 18 0.49592524464969034\n","accuracy:82.319%\n","log_loss 0.5449845854334681\n","********************\n","netloss 19 0.4817962548842914\n","accuracy:82.607%\n","log_loss 0.5484132839747724\n","********************\n","netloss 20 0.4684248009837377\n","accuracy:82.139%\n","log_loss 0.5606090488386127\n","********************\n","Counter 1 of 5\n","netloss 21 0.4591977477622638\n","accuracy:82.715%\n","log_loss 0.5296252385617666\n","********************\n","netloss 22 0.49198838586904237\n","accuracy:83.219%\n","log_loss 0.5489017233982796\n","********************\n","netloss 23 0.44406605452813175\n","accuracy:82.895%\n","log_loss 0.5441632189128716\n","********************\n","Counter 1 of 5\n","netloss 24 0.4353620552704765\n","accuracy:83.147%\n","log_loss 0.5312921233361855\n","********************\n","Counter 2 of 5\n","netloss 25 0.4295067208213392\n","accuracy:83.255%\n","log_loss 0.518556644821292\n","********************\n","netloss 26 0.41265030020838955\n","accuracy:83.543%\n","log_loss 0.5260869869294685\n","********************\n","netloss 27 0.4031405443443865\n","accuracy:84.192%\n","log_loss 0.49401168312741717\n","********************\n","netloss 28 0.3950315336326107\n","accuracy:84.624%\n","log_loss 0.5158696766726665\n","********************\n","netloss 29 0.3900109920944834\n","accuracy:83.651%\n","log_loss 0.5183821632636046\n","********************\n","Counter 1 of 5\n","netloss 30 0.37927825665445136\n","accuracy:83.111%\n","log_loss 0.5384021718284313\n","********************\n","Counter 2 of 5\n","netloss 31 0.3711680128275764\n","accuracy:83.723%\n","log_loss 0.5234774430853781\n","********************\n","Counter 3 of 5\n","netloss 32 0.36658575202418675\n","accuracy:84.732%\n","log_loss 0.4983197101793407\n","********************\n","netloss 33 0.3483771127191457\n","accuracy:84.660%\n","log_loss 0.4902612810455669\n","********************\n","Counter 1 of 5\n","netloss 34 0.3486665400686239\n","accuracy:82.967%\n","log_loss 0.5272285229951064\n","********************\n","Counter 2 of 5\n","netloss 35 0.35631772819143903\n","accuracy:83.399%\n","log_loss 0.5280135482512868\n","********************\n","Counter 3 of 5\n","netloss 36 0.336399997483375\n","accuracy:85.056%\n","log_loss 0.4927082879932678\n","********************\n","netloss 37 0.3321145779569425\n","accuracy:83.363%\n","log_loss 0.5220694908088359\n","********************\n","Counter 1 of 5\n","netloss 38 0.3244216418882223\n","accuracy:84.336%\n","log_loss 0.5186503541640114\n","********************\n","Counter 2 of 5\n","netloss 39 0.3192008273819754\n","accuracy:84.156%\n","log_loss 0.5345605592478263\n","********************\n","Counter 3 of 5\n","netloss 40 0.31541362631835757\n","accuracy:84.444%\n","log_loss 0.5097764898375475\n","********************\n","Counter 4 of 5\n","netloss 41 0.3096799419489466\n","accuracy:84.084%\n","log_loss 0.5408456995687332\n","********************\n","Counter 5 of 5\n","netloss 42 0.30416948147759637\n","accuracy:85.092%\n","log_loss 0.48895593211055693\n","********************\n","netloss 43 0.30745038529704105\n","accuracy:84.984%\n","log_loss 0.5059313475962743\n","********************\n","Counter 1 of 5\n","netloss 44 0.3012018940877679\n","accuracy:85.128%\n","log_loss 0.5310807173142464\n","********************\n","netloss 45 0.2973789716406705\n","accuracy:86.208%\n","log_loss 0.499318479064992\n","********************\n","netloss 46 0.28901922216422643\n","accuracy:85.344%\n","log_loss 0.4975675535095616\n","********************\n","Counter 1 of 5\n","netloss 47 0.29204882417072503\n","accuracy:85.020%\n","log_loss 0.5148164072218526\n","********************\n","Counter 2 of 5\n","netloss 48 0.2962482678869345\n","accuracy:85.380%\n","log_loss 0.5087021455851414\n","********************\n","Counter 3 of 5\n","netloss 49 0.2886094000496709\n","accuracy:85.056%\n","log_loss 0.522517984308327\n","********************\n","Counter 4 of 5\n","****************************************\n","0.8539643108709747\n"]}],"source":["labels=[0,1,2,3,4,5,6,7]\n","list_score=[]\n","for fold, (train_index, test_index) in enumerate(kfold.split(x_train, y_train)):\n","    print(\"train_index\",train_index)\n","    print(\"test_index\",test_index)\n","    ### Dividing data into folds\n","    x_train_fold = x_train[train_index]\n","    x_test_fold = x_train[test_index]\n","    y_train_fold = y_train[train_index]\n","    y_test_fold = y_train[test_index]\n","    train = MyDataset(x_train_fold, y_train_fold)\n","    test = MyDataset(x_test_fold, y_test_fold)\n","    train_loader = DataLoader(train, batch_size = 16, shuffle = True)\n","    test_loader = DataLoader(test, batch_size = 16, shuffle = True)\n","    print(\"fold:\",fold)\n","    max_score=[]\n","    # model = Net().to(device)\n","    best_acc=0\n","    model = AlexNet().to(device)\n","    loss_fn = nn.NLLLoss()\n","    optimizer = torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.5)\n","    for i in range(50):\n","      list1=[]\n","      for t, (data, target) in enumerate(train_loader):\n","        # print(\"t\",t)\n","        data,target = Variable(data.to(device)),Variable(target.to(device))\n","        # print(data.shape)\n","        pred = model(data.double().to(device))\n","        loss = loss_fn(pred,target)\n","        \n","        list1.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # print(\"loss\",loss.item())\n","      print(\"netloss\",i,np.mean(list1))\n","      with torch.no_grad():\n","        list_loss=[]\n","        correct = 0\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data.double().to(device))\n","            # get the index of the max log-probability\n","            pred = output.data.max(1, keepdim=True)[1]\n","            pred_loss=np.exp(output.data.cpu())\n","            logsloss=log_loss(target.cpu().detach().numpy(),pred_loss,labels=labels)\n","            list_loss.append(logsloss)\n","            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","        print('accuracy:{:.3f}%'.format(\n","            100. * correct / len(test_loader.dataset)))\n","        val_acc=correct / len(test_loader.dataset)\n","        print(\"log_loss\",sum(list_loss)/len(list_loss))\n","        print(\"*\"*20)\n","        if val_acc \u003e best_acc:\n","            best_acc = val_acc\n","            es = 0\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            if es \u003e 5:\n","                print(\"Early stopping with best_acc: \", best_acc, \"and val_acc for this epoch: \", val_acc, \"...\")\n","                break\n","    list_score.append(best_acc)\n","    print(\"*\"*40)\n","    del train,x_train_fold,train_loader,test_loader,test,y_test_fold,x_test_fold,y_train_fold\n","    import gc\n","    gc.collect()\n","    time.sleep(20)\n","from numpy import mean\n","print(mean(list_score))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1657723147953,"user":{"displayName":"zhen fei","userId":"06736413076610031297"},"user_tz":-480},"id":"UKTcuoPiNrwP","outputId":"3c678e34-e591-42a4-8ea8-46df0eb3cafe"},"outputs":[{"data":{"text/plain":["0.8539643108709747"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["mean(list_score)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Copy of letnet.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":0}